{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Crameri-Tackley model\n",
    "=======\n",
    "\n",
    "From Cramer and Tackley 2015\n",
    "--------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "References\n",
    "====\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load python functions needed for underworld. Some additional python functions from os, math and numpy used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "288"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "96*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "#import matplotlib.pyplot as pyplot\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set physical constants and parameters, including the Rayleigh number (*RA*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Do you want to write hdf5 files - Temp, RMS, viscosity, stress?\n",
    "writeFiles = True\n",
    "loadTemp = False\n",
    "refineMesh = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ETA_T = 1e5\n",
    "\n",
    "newvisc= math.exp(math.log(ETA_T)*0.53)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "446.6835921509633"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "newvisc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#No rheology Constants\n",
    "###########\n",
    "\n",
    "TS  = 0          # surface temperature\n",
    "TB  = 1          # bottom boundary temperature (melting point)\n",
    "\n",
    "\n",
    "D = 2890.\n",
    "\n",
    "MINX = -1.\n",
    "#Mesh refinement parameter\n",
    "ALPHA = 11.\n",
    "\n",
    "stickyAir = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "if MINX == 0.:\n",
    "    squareModel = True\n",
    "else: \n",
    "    squareModel = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##########\n",
    "#variables, these can be defined with STDIN,\n",
    "##########\n",
    "#The == '-f': check is just to check if we're running a notebook - careful, haven't tested\n",
    "    \n",
    "#Watch the type assignemnt on sys.argv[1]\n",
    "\n",
    "RES = 128\n",
    "DEFAULTDT  = 10000\n",
    "#ModIt   = str(DEFAULT)\n",
    "\n",
    "\n",
    "############\n",
    "#Need to manually set these two\n",
    "############\n",
    "Model = \"R\"\n",
    "ModNum = 2\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModIt = \"Base\"\n",
    "elif sys.argv[1] == '-f':\n",
    "    ModIt = \"Base\"\n",
    "else:\n",
    "    ModIt = str(sys.argv[1])\n",
    "    DEFAULTDT = int(sys.argv[1])\n",
    "    \n",
    "    \n",
    "#if len(sys.argv) == 1:\n",
    "#    RES = DEFAULT\n",
    "#elif sys.argv[1] == '-f':\n",
    "#    RES = DEFAULT\n",
    "#else:\n",
    "#    RES = int(sys.argv[1])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\"\n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '_' + str(ModIt) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "dim = 2          # number of spatial dimensions\n",
    "\n",
    "\n",
    "if MINX == 0.:\n",
    "    Xres = RES\n",
    "else:\n",
    "    Xres = 2*RES\n",
    "    \n",
    "if stickyAir:\n",
    "    Yres = RES + 4\n",
    "    MAXY = float(Yres)/RES\n",
    "    \n",
    "else:\n",
    "    Yres = RES\n",
    "    MAXY = 1.\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.03125"
      ]
     },
     "execution_count": 247,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MAXY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('results/R/2/', 'results/R/2/checkpoint/')"
      ]
     },
     "execution_count": 248,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputPath, checkpointPath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 264)"
      ]
     },
     "execution_count": 249,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xres, Yres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.03125, 0.00390625, 11.2890625)"
      ]
     },
     "execution_count": 250,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yelsize = MAXY/Yres\n",
    "MAXY, yelsize, yelsize*D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select which case of viscosity from Tosi et al (2015) to use. Adjust the yield stress to be =1 for cases 1-4, or between 3.0 and 5.0 (in increments of 0.1) in case 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set output file and directory for results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create mesh objects. These store the indices and spatial coordiates of the grid points on the mesh."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "elementMesh = uw.mesh.FeMesh_Cartesian( elementType=(\"Q1/dQ0\"), \n",
    "                                         elementRes=(Xres, Yres), \n",
    "                                           minCoord=(MINX,0.), \n",
    "                                           maxCoord=(1.,MAXY), periodic=[True,False] )\n",
    "linearMesh   = elementMesh\n",
    "constantMesh = elementMesh.subMesh "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Finite Element (FE) variables for the velocity, pressure and temperature fields. The last two of these are scalar fields needing only one value at each mesh point, while the velocity field contains a vector of *dim* dimensions at each mesh point."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "velocityField    = uw.fevariable.FeVariable( feMesh=linearMesh,   nodeDofCount=dim )\n",
    "pressureField    = uw.fevariable.FeVariable( feMesh=constantMesh, nodeDofCount=1 )\n",
    "temperatureField = uw.fevariable.FeVariable( feMesh=linearMesh,   nodeDofCount=1 )\n",
    "temperatureDotField = uw.fevariable.FeVariable( feMesh=linearMesh,      nodeDofCount=1 )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create some dummy fevariables for doing top and bottom boundary calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Refine mesh"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "if refineMesh:\n",
    "    alpha=ALPHA\n",
    "    newys = []\n",
    "    newxs = []\n",
    "    for index, coord in enumerate(linearMesh.data):\n",
    "        y0 = coord[1]\n",
    "        x0 = abs(coord[0])\n",
    "        if y0 >= 1.0:\n",
    "            newy = y0\n",
    "        else:\n",
    "            newy = (math.log(alpha*y0 + math.e) - 1)*(1/(math.log(alpha + math.e) - 1))\n",
    "        newx = (math.log((alpha/2.)*x0 + math.e) - 1)*(1/(math.log((alpha/2.) + math.e) - 1))\n",
    "        if coord[0] <= 0:\n",
    "            newx = -1.*newx\n",
    "        newys.append(newy)\n",
    "        newxs.append(newx)\n",
    "        \n",
    "    with linearMesh.deform_mesh():\n",
    "        linearMesh.data[:,1] = newys\n",
    "        linearMesh.data[:,0] = newxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#THis one for the rectangular mesh\n",
    "\n",
    "if refineMesh:\n",
    "    alpha = ALPHA\n",
    "    newys = []\n",
    "    newxs = []\n",
    "    for index, coord in enumerate(linearMesh.data):\n",
    "        y0 = coord[1]\n",
    "        x0 = abs(coord[0])\n",
    "        if y0 == MAXY:\n",
    "            newy = y0\n",
    "        else:\n",
    "            ynorm = y0/MAXY\n",
    "            newy = MAXY*(math.log(alpha*ynorm + math.e) - 1)*(1/(math.log(alpha + math.e) - 1))\n",
    "        if coord[0] > 0:\n",
    "            newx = (math.e**(x0*(math.log((alpha/2.) + math.e) - 1) + 1 ) - math.e)/(alpha/2.)     \n",
    "        else:\n",
    "            newx = -1.*(math.e**(x0*(math.log((alpha/2.) + math.e) - 1) + 1 ) - math.e)/(alpha/2.)\n",
    "        newys.append(newy)\n",
    "        newxs.append(newx)\n",
    "        #print y0,newy\n",
    "        \n",
    "    with linearMesh.deform_mesh():\n",
    "            linearMesh.data[:,1] = newys\n",
    "            linearMesh.data[:,0] = newxs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Check if starting from checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "results/R/2/checkpoint/ is empty\n"
     ]
    }
   ],
   "source": [
    "checkdirs = []\n",
    "for dirpath, dirnames, files in os.walk(checkpointPath):\n",
    "    if files:\n",
    "        print dirpath, 'has files'\n",
    "        checkpointLoad = True\n",
    "        checkdirs.append(dirpath)\n",
    "    if not files:\n",
    "        print dirpath, 'is empty'\n",
    "        checkpointLoad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ICs and BCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dansandiford/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:16: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "/Users/dansandiford/anaconda/lib/python2.7/site-packages/IPython/kernel/__main__.py:16: RuntimeWarning: invalid value encountered in double_scalars\n"
     ]
    }
   ],
   "source": [
    "# Initialise data.. Note that we are also setting boundary conditions here\n",
    "velocityField.data[:] = [0.,0.]\n",
    "pressureField.data[:] = 0.\n",
    "temperatureField.data[:] = 0.\n",
    "temperatureDotField.data[:] = 0.\n",
    "\n",
    "def wbl(x, w0 = 0.06):\n",
    "    delx = 1- abs(x)\n",
    "    Wbl = w0*math.sqrt(delx)\n",
    "    return Wbl\n",
    "\n",
    "wbl(1)\n",
    "\n",
    "\n",
    "def tempf(z,w,t0=0.64):\n",
    "    temp = t0*math.erf((1-z)/w)\n",
    "    return temp\n",
    "\n",
    "for index, coord in enumerate(linearMesh.data):\n",
    "    w = wbl(coord[0])\n",
    "    t = tempf(coord[1], w)\n",
    "    temperatureField.data[index] = t\n",
    "\n",
    "\n",
    "for index, coord in enumerate(linearMesh.data):\n",
    "    if abs(coord[0]) < wbl(0)/2. and coord[1] > 0.5:\n",
    "        w = wbl(0)/2.\n",
    "        d = w - abs(coord[0])\n",
    "        t = tempf(d, coord[1], w)\n",
    "        temperatureField.data[index] = t\n",
    "        \n",
    "        \n",
    "\n",
    "#Set sticky air Temp to zero\n",
    "\n",
    "for index, coord in enumerate(linearMesh.data):\n",
    "    if coord[1] > 1:\n",
    "        temperatureField.data[index] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figTemp = glucifer.Figure()\n",
    "figTemp + glucifer.objects.Surface(elementMesh, temperatureField)\n",
    "figTemp + glucifer.objects.Mesh(linearMesh)\n",
    "figTemp.show()\n",
    "figTemp.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#For notebook runs\n",
    "#ModIt = \"96\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#a little workaround for change in Load Style\n",
    "##############\n",
    "\n",
    "import libUnderworld\n",
    "def _oldload(self, path):\n",
    "    libUnderworld.StgFEM.FeVariable_ReadFromFile( self._cself, path)\n",
    "    \n",
    "uw.fevariable._fevariable.FeVariable._oldload = _oldload # monkey patch fevariable\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the actual sets \n",
    "#\n",
    "#  HJJJJJJH\n",
    "#  I      I\n",
    "#  I      I\n",
    "#  I      I\n",
    "#  HJJJJJJH\n",
    "#  \n",
    "#  Note that H = I & J \n",
    "\n",
    "# Note that we use operator overloading to combine sets\n",
    "IWalls = linearMesh.specialSets[\"MinI_VertexSet\"] + linearMesh.specialSets[\"MaxI_VertexSet\"]\n",
    "JWalls = linearMesh.specialSets[\"MinJ_VertexSet\"] + linearMesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "TWalls = linearMesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "BWalls = linearMesh.specialSets[\"MinJ_VertexSet\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now setup the dirichlet boundary condition\n",
    "# Note that through this object, we are flagging to the system \n",
    "# that these nodes are to be considered as boundary conditions. \n",
    "# Also note that we provide a tuple of sets.. One for the Vx, one for Vy.\n",
    "freeslipBC = uw.conditions.DirichletCondition(     variable=velocityField, \n",
    "                                              nodeIndexSets=(TWalls, JWalls) )\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "tempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              nodeIndexSets=(TWalls,) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Add Random 125 K temp perturbation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempNump = temperatureField.data\n",
    "\n",
    "#In gerneral we only want to do this on the initial setup, not restarts\n",
    "\n",
    "if not checkpointLoad:\n",
    "    for index, coord in enumerate(linearMesh.data):\n",
    "        pertCoeff = (0.05*np.random.rand(1)[0])\n",
    "        ict = tempNump[index]\n",
    "        tempNump[index] = ict + pertCoeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Reset bottom Dirichlet conds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set temp boundaries \n",
    "# on the boundaries\n",
    "for index in linearMesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = 0.64\n",
    "for index in linearMesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkdirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gSwarm = uw.swarm.Swarm( feMesh=elementMesh )\n",
    "materialVariable = gSwarm.add_variable( dataType=\"char\", count=1 )\n",
    "rockIntVar = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "airIntVar = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "lithIntVar = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "\n",
    "varlist = [materialVariable, rockIntVar, airIntVar, lithIntVar]\n",
    "varnames = ['materialVariable', 'rockIntVar', 'airIntVar', 'lithIntVar']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Swarm checkpoint load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mantleIndex = 0\n",
    "lithosphereIndex = 1\n",
    "crustIndex = 2\n",
    "airIndex = 3\n",
    "\n",
    "#All depth conditions are given as (km/D) where D is the length scale, \n",
    "#note that 'model depths' are used, e.g. 1-z, where z is the vertical Underworld coordinate\n",
    "#All temp conditions are in dimensionless temp. [0. - 1.]\n",
    "\n",
    "#A few paramters defining lengths scales\n",
    "\n",
    "Crust = 18.\n",
    "CrustM = Crust/D\n",
    "\n",
    "\n",
    "#######Setup some variables which help define condtions\n",
    "#rock-air topography limits\n",
    "dz = 15./D\n",
    "\n",
    "avgtemp = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.006228373702422145"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CrustM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsorted(checkdirs)[-1]\n",
    "    temperatureField._oldload(os.path.join(checkpointLoadDir, \"temperatureField\" + \".hdf5\"))\n",
    "    pressureField._oldload(os.path.join(checkpointLoadDir, \"pressureField\" + \".hdf5\"))\n",
    "    velocityField._oldload(os.path.join(checkpointLoadDir, \"velocityField\" + \".hdf5\"))\n",
    "    gSwarm.load(os.path.join(checkpointLoadDir, \"swarm\" + \".h5\"))\n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.load(os.path.join(checkpointLoadDir,varnames[ix] + \".h5\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    # Layouts are used to populate the swarm across the whole domain\n",
    "    # Create the layout object\n",
    "    #layout = uw.swarm.layouts.GlobalSpaceFillerLayout( swarm=gSwarm, particlesPerCell=20)\n",
    "    layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=15)\n",
    "    # Now use it to populate.\n",
    "    gSwarm.populate_using_layout( layout=layout )\n",
    "\n",
    "    # Lets initialise the 'materialVariable' data to represent different materials\n",
    "    # Set the material to heavy everywhere via the numpy array\n",
    "    materialVariable.data[:] = mantleIndex\n",
    "    \n",
    "    \n",
    "    #Set initial air and crust materials (allow the graph to take care of lithsophere)\n",
    "    #########\n",
    "    #This initial material setup will be model dependent\n",
    "    #########\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "        if (1. - gSwarm.particleCoordinates.data[particleID][1]) < 0:\n",
    "                 materialVariable.data[particleID] = airIndex\n",
    "        elif (1. - gSwarm.particleCoordinates.data[particleID][1]) < CrustM:\n",
    "                 materialVariable.data[particleID] = crustIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "#    if (abs(gSwarm.particleCoordinates.data[particleID][0]) < CrustM) and (gSwarm.particleCoordinates.data[particleID][1] < 1.0):\n",
    "#        materialVariable.data[particleID] = crustIndex\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Material Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Important: This is a quick fix for a bug that arises in parallel runs\n",
    "##############\n",
    "material_list = [0,1,2,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unique values after swarm has loaded:[0 2 3]\n"
     ]
    }
   ],
   "source": [
    "print( \"unique values after swarm has loaded:\" + str(np.unique(materialVariable.data[:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "\n",
    "#######Graph object\n",
    "DG = nx.DiGraph(field=\"Depth\")\n",
    "\n",
    "#######Nodes\n",
    "#Note that the order of materials, deepest to shallowest is important \n",
    "DG.add_node(0, mat='mantle')\n",
    "DG.add_node(1, mat='lithosphere')\n",
    "DG.add_node(2, mat='crust')\n",
    "DG.add_node(3, mat='air')\n",
    "\n",
    "\n",
    "labels=dict((n,d['mat']) for n,d in DG.nodes(data=True))\n",
    "pos=nx.spring_layout(DG) \n",
    "\n",
    "\n",
    "#######Edges\n",
    "#anything to air\n",
    "DG.add_edges_from([(0,3),(1,3), (2,3)])\n",
    "DG[0][3]['depthcondition'] = -1*dz\n",
    "DG[1][3]['depthcondition'] = -1*dz\n",
    "DG[2][3]['depthcondition'] = -1*dz\n",
    "\n",
    "\n",
    "#Anything to mantle\n",
    "DG.add_edges_from([(2,0), (3,0), (1,0)])\n",
    "DG[3][0]['depthcondition'] = dz\n",
    "DG[2][0]['depthcondition'] = (300./D)\n",
    "DG[1][0]['depthcondition'] = (660./D) #This means we're going to kill lithosphere at the 660.\n",
    "\n",
    "\n",
    "#Anything to lithsphere\n",
    "DG.add_edges_from([(0,1),(3,1)])\n",
    "DG[0][1]['depthcondition'] = 200./D\n",
    "DG[0][1]['avgtempcondition'] = 0.75*avgtemp #definition of thermal lithosphere\n",
    "\n",
    "\n",
    "#Anything to crust\n",
    "DG.add_edges_from([(0,2), (1,2)])\n",
    "DG[0][2]['depthcondition'] = CrustM\n",
    "DG[1][2]['depthcondition'] = CrustM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DG.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_nodes = []\n",
    "for node in DG.nodes():\n",
    "    if not node in material_list:\n",
    "        remove_nodes.append(node)\n",
    "        \n",
    "for rmnode in remove_nodes:\n",
    "    DG.remove_node(rmnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2, 3]"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DG.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#remove_nodes = []\n",
    "#for node in DG.nodes_iter():\n",
    "#    if not node in material_list:\n",
    "#        remove_nodes.append(node)\n",
    "        \n",
    "#for rmnode in remove_nodes:\n",
    "#    DG.remove_node(rmnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A Dictionary to map strings in the graph (e.g. 'depthcondition') to particle data arrays\n",
    "\n",
    "particledepths = 1. - gSwarm.particleCoordinates.data[:,1]\n",
    "particletemps = temperatureField.evaluate(gSwarm)[:,0]\n",
    "\n",
    "conditionmap = {}\n",
    "\n",
    "conditionmap['depthcondition'] = {}\n",
    "conditionmap['depthcondition']['data'] = particledepths\n",
    "conditionmap['avgtempcondition'] = {}\n",
    "conditionmap['avgtempcondition']['data'] = particletemps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_swarm(graph, particleIndex):\n",
    "    \"\"\"\n",
    "    This function takes the materials graph (networkx.DiGraph), and a particle index,\n",
    "    then determines if a material update is required \n",
    "    and if so, returns the new materialindex\n",
    "    Args:\n",
    "        graph (networkx.DiGraph): Directed multigraph representing the transformation of material types\n",
    "        particleIndex (int): the particle index as corressponding to the index in the swarm data arrays\n",
    "    Returns:\n",
    "        if update is required the function returns the the new material variable (int) \n",
    "        else returns None\n",
    "    Raises:\n",
    "        TypeError: not implemented\n",
    "        ValueError: not implemented\n",
    "    \"\"\"\n",
    "    ##Egde gives links to other materials, we then query the conditions to see if we should change materials\n",
    "    matId = materialVariable.data[particleIndex][0]\n",
    "    innerchange = False\n",
    "    outerchange = False\n",
    "    for edge in graph[matId]:\n",
    "        if outerchange:\n",
    "            break\n",
    "        for cond in graph[matId][edge].keys():\n",
    "            outerchange = False\n",
    "            if innerchange: #found a complete transition, break inner loop\n",
    "                break\n",
    "            currentparticlevalue = conditionmap[cond]['data'][particleIndex]\n",
    "            crossover = graph[matId][edge][cond]\n",
    "            if ((matId > edge) and (currentparticlevalue > crossover)):\n",
    "                innerchange = False # continue on, \n",
    "                if graph[matId][edge].keys()[-1] == cond:\n",
    "                    outerchange = True\n",
    "                    innerchange = edge\n",
    "                    break\n",
    "            elif ((matId < edge) and (currentparticlevalue < crossover)):\n",
    "                innerchange = False\n",
    "                if graph[matId][edge].keys()[-1] == cond:\n",
    "                    outerchange = True\n",
    "                    innerchange = edge\n",
    "                    break\n",
    "            else:\n",
    "                #condition not met, break outer loop, go to next edge, outerchange should still be False\n",
    "                break\n",
    "    if type(innerchange) == int:\n",
    "        return innerchange"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "                check = update_swarm(DG, particleID)\n",
    "                #print check\n",
    "                if check > -1:\n",
    "                    #number_updated += 1\n",
    "                    materialVariable.data[particleID] = check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleanse the swarm of its sins\n",
    "#For some Material Graphs, the graph may have to be treaversed more than once\n",
    "\n",
    "check = -1\n",
    "number_updated = 1\n",
    "\n",
    "while number_updated != 0:\n",
    "    number_updated = 0\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "                check = update_swarm(DG, particleID)\n",
    "                if check > -1:\n",
    "                    number_updated += 1\n",
    "                    materialVariable.data[particleID] = check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#figtemp = plt.Figure()\n",
    "#tempminmax = fn.view.min_max(temperatureField)\n",
    "#figtemp.Surface(temperatureField, linearMesh)\n",
    "#figtemp.VectorArrows(velocityField, linearMesh, lengthScale=0.5/velmax, arrowHeadSize=0.2 )\n",
    "#figtemp.Points( swarm=gSwarm, colourVariable=materialVariable , pointSize=1.0)\n",
    "#figtemp.Mesh(linearMesh, colourBar=False)\n",
    "#figtemp.show()\n",
    "#figtemp.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Set the values for the masking swarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup up a masking Swarm variable for the integrations.\n",
    "#Two possible problems? \n",
    "#does it work in parallel,\n",
    "#How do we mange advecting this swarm?\n",
    "#(might be best to just rebuild it every timestep, that way we only focus on advecting the material swarm)\n",
    "\n",
    "rockIntVar.data[:] = 0.\n",
    "notair = np.where(materialVariable.data != airIndex)\n",
    "rockIntVar.data[notair] = 1.\n",
    "\n",
    "airIntVar.data[:] = 0.\n",
    "notrock = np.where(materialVariable.data == airIndex)\n",
    "airIntVar.data[notrock] = 1.\n",
    "\n",
    "lithIntVar.data[:] = 0.\n",
    "islith = np.where((materialVariable.data == lithosphereIndex) | (materialVariable.data == crustIndex))\n",
    "lithIntVar.data[islith] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "##Set up a swarm for surface integrations¶\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24.0"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.floor(10.*156/64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "snum = 1000.\n",
    "dx = (linearMesh.data[:,0].max()- linearMesh.data[:,0].min())/snum\n",
    "yp = 0.9947 #1. - yelsize/2. at res = 96\n",
    "\n",
    "linearMesh.data[:,0].max()\n",
    "xps = np.linspace(linearMesh.data[:,0].min(),linearMesh.data[:,0].max(), snum)\n",
    "yps = [yp for i in xps]\n",
    "\n",
    "surfintswarm = uw.swarm.Swarm( feMesh=elementMesh )\n",
    "dumout = surfintswarm.add_particles_with_coordinates(np.array((xps,yps)).T)\n",
    "\n",
    "yps = [ 1.- yp  for i in xps]\n",
    "\n",
    "baseintswarm = uw.swarm.Swarm( feMesh=elementMesh )\n",
    "dumout = baseintswarm.add_particles_with_coordinates(np.array((xps,yps)).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# visualise\n",
    "#fig1 = plt.Figure()\n",
    "#fig1.Points( swarm=surfintswarm, pointSize=10.0)\n",
    "#fig1.Points( swarm=baseintswarm, pointSize=10.0)\n",
    "#fig1.Points( swarm=gSwarm,colourVariable=rockIntVar)\n",
    "#fig1.VectorArrows(velocityField, linearMesh, lengthScale=0.0002)\n",
    "#fig1.Surface(temperatureField, linearMesh)\n",
    "#\n",
    "#fig1.Mesh(linearMesh, colourBar=False)\n",
    "#fig1.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Material properties\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Make variables required for plasticity\n",
    "\n",
    "secinvCopy = fn.tensor.second_invariant( \n",
    "                    fn.tensor.symmetric( \n",
    "                        velocityField.gradientFn ))\n",
    "\n",
    "coordinate = fn.input()\n",
    "\n",
    "depth = 1. - coordinate[1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "depthField = uw.fevariable.FeVariable( feMesh=linearMesh,   nodeDofCount=1 )\n",
    "\n",
    "depthField.data[:] = depth.evaluate(linearMesh)\n",
    "depthField.data[np.where(depthField.data[:] < 0.)[0]] = 0.\n",
    "#depthdata = depth.evaluate(linearMesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dimensional parameters\n",
    " \n",
    "cohesion = 1e7 #i.e. 10 Mpa\n",
    "D = 2890.\n",
    "E = 240000. # J mol−1\n",
    "R = 8.314 # m^3 mol\n",
    "V = 6.34*(10**-7)\n",
    "T0 = 273.\n",
    "Tr = 1600.\n",
    "rd = 0.0\n",
    "g = 9.8\n",
    "delT = 2500.\n",
    "rho0 = 3300.\n",
    "eta0 = 1e23\n",
    "k = 10**(-6) \n",
    "fcb = 0.6 #friction coefficient from Byerlees' law\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#scaling factors\n",
    "\n",
    "stressscale  = (eta0*k)/(D*1000)**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11.5467885494 2.85377690546 0.64 0.1092 1.0 835.21 4683653.88876\n"
     ]
    }
   ],
   "source": [
    "#Non-dimensional parameters\n",
    "\n",
    "cohesionp = cohesion/stressscale\n",
    "\n",
    "fc = 0.1 #mantle friction coefficient\n",
    "\n",
    "\n",
    "fcc = 0.01 #crust friction coefficient\n",
    "Ra = 1e6                                                                                                                                                                                                                                                   \n",
    "Ep = E/(R*delT)\n",
    "Vp = (rho0*9.81*V*(D*1000))/(R*delT)\n",
    "Trp =1600./2500.\n",
    "T0p = T0/2500.\n",
    "rdp = 1.\n",
    "fcbp = (fcb*rho0*g*(D*1000)**3)/(k*eta0)\n",
    "\n",
    "print Ep, Vp, Trp, T0p,rdp, cohesionp,fcbp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Compositional Rayligh number of rock-water \n",
    "\n",
    "g = 9.81\n",
    "rho = 3300\n",
    "a = 1.25*10**-5\n",
    "kappa = 10**-6\n",
    "dT = 2500\n",
    "#eta0 = rho*g*a*dT*((D*1e3)**3)/(Ra*kappa)\n",
    "eta0 = 1e23\n",
    "#Composisitional Rayleigh number\n",
    "Rc = (3300*g*(D*1000)**3)/(eta0*kappa)\n",
    "\n",
    "CompRAfact = Rc/Ra\n",
    "\n",
    "airviscosity = 0.001\n",
    "airdensity = Ra*CompRAfact\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1e+23"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eta0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pressureFieldCopy = uw.fevariable.FeVariable( feMesh=constantMesh, nodeDofCount=1)\n",
    "pressureFieldCopy.data[:] = (pressureField.data - pressureField.data.max())*-1.\n",
    "\n",
    "lithopressureField = uw.fevariable.FeVariable( feMesh=constantMesh, nodeDofCount=1)\n",
    "lithopressuregrad = rho0*g*(D*1e3)**3/(eta0*kappa)\n",
    "\n",
    "for index, coord in enumerate(constantMesh.data):\n",
    "    lithopressureField.data[index] = (1.-coord[1])*lithopressuregrad\n",
    "lithopressureField.data[lithopressureField.data < 0] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, Crameri and Tackley give the dimensionless cohesion as well as the dimensionless yield stress gradient. But the latter is given as a function of dimensionless (lithostatic) pressure, whereas it is easier to use dimensionless depth. Easy, multiply the dimensionless depth by $\\rho g D$, divide by the stress scale, $\\frac{\\eta \\kappa}{D^2}$ then use the same dimensionless yeild stress gradient ($\\mu$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "secinvCopy = fn.tensor.second_invariant( \n",
    "                    fn.tensor.symmetric( \n",
    "                        velocityField.gradientFn ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#Determine yield criterion for depth (rather than pressure as given in Crameri)\n",
    "\n",
    "lithopressuregrad = rho0*g*(D*1e3)**3/(eta0*kappa)\n",
    "\n",
    "\n",
    "############\n",
    "#Mantle\n",
    "############\n",
    "\n",
    "#Linear viscosity\n",
    "coordinate = fn.input()\n",
    "arhennius = fn.misc.min(1e5,fn.math.exp(((Ep + Vp*(1.-coordinate[1]))/(temperatureField + T0p)) - ((Ep + Vp*(1.- rdp))/(Trp + T0p))))\n",
    "\n",
    "#Psuedo-plastic \n",
    "#ys =  1577. + (depth*fc*lithopressuregrad)\n",
    "ys =  10000.\n",
    "yss = fn.misc.max(1577., ys)\n",
    "plasticvisc = yss/(secinvCopy/math.sqrt(0.5))\n",
    "plastic = fn.misc.max(1e-4,plasticvisc) #extra factor to account for underworld second invariant form\n",
    "\n",
    "#combine these\n",
    "mantleviscosityFn = fn.exception.SafeMaths(fn.misc.min(arhennius, plastic))\n",
    "\n",
    "############\n",
    "#crust\n",
    "############\n",
    "\n",
    "#ysc = (1577./10.) + (depth*(fc/100.)*lithopressuregrad)\n",
    "ysc = 1000.\n",
    "ycs = fn.misc.max((1577./10.), ysc)\n",
    "crustplasticvisc = ycs/(secinvCopy/math.sqrt(0.5))\n",
    "crustplastic = fn.misc.max(1e-4,crustplasticvisc) #extra factor to account for underworld second invariant form\n",
    "crustviscosityFn = fn.exception.SafeMaths(fn.misc.min(arhennius, crustplastic))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7814055.212370002"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lithopressuregrad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up simulation parameters and functions\n",
    "====\n",
    "\n",
    "Here the functions for density, viscosity etc. are set. These functions and/or values are preserved for the entire simulation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Here we set a viscosity value of '1.' for both materials\n",
    "viscosityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:airviscosity, lithosphereIndex:mantleviscosityFn, crustIndex:mantleviscosityFn,mantleIndex:mantleviscosityFn} )\n",
    "\n",
    "densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:airdensity, lithosphereIndex:Ra*temperatureField, crustIndex:Ra*temperatureField, mantleIndex:Ra*temperatureField} )\n",
    "\n",
    "# Define our gravity using a python tuple (this will be automatically converted to a function)\n",
    "gravity = ( 0.0, 1.0 )\n",
    "\n",
    "buoyancyFn = gravity*densityMapFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7.814055212370001"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "airdensity/Ra"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Stokes system, solvers, advection-diffusion\n",
    "------\n",
    "\n",
    "Setup linear Stokes system to get the initial velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We first set up a l\n",
    "stokesPIC = uw.systems.Stokes(velocityField=velocityField, \n",
    "                              pressureField=pressureField,\n",
    "                              conditions=[freeslipBC,],\n",
    "#                              viscosityFn=viscosityFn1, \n",
    "                              viscosityFn=fn.exception.SafeMaths(arhennius), \n",
    "                              bodyForceFn=buoyancyFn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do one solve with linear viscosity to get the initial strain rate invariant. This solve step also calculates a 'guess' of the the velocity field based on the linear system, which is used later in the non-linear solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not checkpointLoad:\n",
    "    #stokesPIC.solve()\n",
    "    solver = uw.systems.Solver(stokesPIC)\n",
    "    solver.options.main.Q22_pc_type='uw'\n",
    "    solver.options.A11.ksp_rtol=1e-6\n",
    "    solver.options.scr.ksp_rtol=1e-5\n",
    "    solver.options.scr.use_previous_guess = True\n",
    "    solver.options.scr.ksp_set_min_it_converge = 6\n",
    "    solver.options.mg.levels = 4\n",
    "    solver.options.A11.ksp_monitor=''\n",
    "    solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Switch particle escape on, this will also trigger the inflow population control \n",
    "gSwarm.particleEscape = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Setup the Stokes system again, now with linear or nonlinear visocity viscosity.\n",
    "stokesPIC2 = uw.systems.Stokes(velocityField=velocityField, \n",
    "                              pressureField=pressureField,\n",
    "                              conditions=[freeslipBC,],\n",
    "                              viscosityFn=fn.exception.SafeMaths(viscosityMapFn), \n",
    "                              bodyForceFn=buoyancyFn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "solver = uw.systems.Solver(stokesPIC2) # altered from PIC2\n",
    "\n",
    "solver.options.main.Q22_pc_type='uwscale'  # also try 'gtkg', 'gkgdiag' and 'uwscale'\n",
    "solver.options.main.penalty = 1.0\n",
    "solver.options.A11.ksp_rtol=1e-6\n",
    "solver.options.scr.ksp_rtol=1e-5\n",
    "solver.options.scr.use_previous_guess = True\n",
    "solver.options.scr.ksp_set_min_it_converge = 1\n",
    "solver.options.scr.ksp_set_max_it = 100\n",
    "solver.options.mg.levels = 4\n",
    "solver.options.mg.mg_levels_ksp_type = 'chebyshev'\n",
    "solver.options.mg_accel.mg_accelerating_smoothing = True\n",
    "solver.options.mg_accel.mg_accelerating_smoothing_view = False\n",
    "solver.options.mg_accel.mg_smooths_to_start = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver = uw.systems.Solver(stokesPIC2) # altered from PIC2\n",
    "\n",
    "\n",
    "\n",
    "solver.options.main.Q22_pc_type='uw'\n",
    "solver.options.A11.ksp_rtol=1e-6\n",
    "solver.options.scr.ksp_rtol=1e-5\n",
    "solver.options.scr.use_previous_guess = True\n",
    "solver.options.scr.ksp_set_min_it_converge = 6\n",
    "\n",
    "solver.options.mg.levels = 4\n",
    "\n",
    "solver.options.A11.ksp_monitor=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object docstring:\n",
      "\n",
      "None\n",
      "Object initialiser docstring:\n",
      "\n",
      "x.__init__(...) initializes x; see help(type(x)) for signature\n"
     ]
    }
   ],
   "source": [
    "uw.help(solver.print_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve for initial pressure and velocity using a quick non-linear Picard iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#solver.solve(nonLinearIterate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "if not checkpointLoad:\n",
    "    solver.solve(nonLinearIterate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('ksp_monitor', '')\n",
      "('_mg_active', True)\n",
      "('ksp_type', 'fgmres')\n",
      "('ksp_rtol', 1e-06)\n",
      "('_mg_active', True)\n",
      "('ksp_type', 'fgmres')\n",
      "('ksp_rtol', 1e-05)\n"
     ]
    }
   ],
   "source": [
    "solver.options.A11.list()\n",
    "solver.options.backsolveA11.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*fgmres:\n",
    "flexible gmres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an advective-diffusive system\n",
    "=====\n",
    "\n",
    "Setup the system in underworld by flagging the temperature and velocity field variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create advdiff system\n",
    "advDiff = uw.systems.AdvectionDiffusion( temperatureField, temperatureDotField, velocityField, diffusivity=1., conditions=[tempBC,] )\n",
    "\n",
    "advector = uw.systems.SwarmAdvector( swarm=gSwarm, velocityField=velocityField, order=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics for benchmark\n",
    "=====\n",
    "\n",
    "Define functions to be used in the time loop. For cases 1-4, participants were asked to report a number of diagnostic quantities to be measured after reaching steady state:\n",
    "\n",
    "* Average temp... $$  \\langle T \\rangle  = \\int^1_0 \\int^1_0 T \\, dxdy $$\n",
    "* Top and bottom Nusselt numbers... $$N = \\int^1_0 \\frac{\\partial T}{\\partial y} \\rvert_{y=0/1} \\, dx$$\n",
    "* RMS velocity over the whole domain, surface and max velocity at surface\n",
    "* max and min viscosity over the whole domain\n",
    "* average rate of work done against gravity...$$\\langle W \\rangle = \\int^1_0 \\int^1_0 T u_y \\, dx dy$$\n",
    "* and the average rate of viscous dissipation...$$\\langle \\Phi \\rangle = \\int^1_0 \\int^1_0 \\tau_{ij} \\dot \\epsilon_{ij} \\, dx dy$$\n",
    "\n",
    "* In steady state, if thermal energy is accurately conserved, the difference between $\\langle W \\rangle$ and $\\langle \\Phi \\rangle / Ra$ must vanish, so also reported is the percentage error: \n",
    "\n",
    "$$ \\delta = \\frac{\\lvert \\langle W \\rangle - \\frac{\\langle \\Phi \\rangle}{Ra} \\rvert}{max \\left(  \\langle W \\rangle,  \\frac{\\langle \\Phi \\rangle}{Ra}\\right)} \\times 100% $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup some Integrals. We want these outside the main loop...\n",
    "tempVariable = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "tempVariable.data[:] = temperatureField.evaluate(gSwarm)[:]\n",
    "tempint = uw.utils.Integral((tempVariable*rockIntVar), linearMesh)\n",
    "\n",
    "\n",
    "areaint = uw.utils.Integral((1.*rockIntVar),linearMesh)\n",
    "\n",
    "v2int = uw.utils.Integral(fn.math.dot(velocityField,velocityField)*rockIntVar, linearMesh)\n",
    "\n",
    "\n",
    "dwint = uw.utils.Integral(temperatureField*velocityField[1]*rockIntVar, linearMesh)\n",
    "\n",
    "secinv = fn.tensor.second_invariant(\n",
    "                    fn.tensor.symmetric(\n",
    "                        velocityField.gradientFn ))\n",
    "\n",
    "sinner = fn.math.dot(secinv,secinv)\n",
    "vdint = uw.utils.Integral((4.*mantleviscosityFn*sinner)*rockIntVar, linearMesh)\n",
    "vdintair = uw.utils.Integral((4.*mantleviscosityFn*sinner)*airIntVar, linearMesh)\n",
    "vdintlith = uw.utils.Integral((4.*mantleviscosityFn*sinner)*lithIntVar, linearMesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_temp():\n",
    "    return tempint.evaluate()[0]\n",
    "\n",
    "#This one gets cleaned up when Surface integrals are available\n",
    "def nusselt(tempfield, swarm, dx):\n",
    "    #Update the swarm variable\n",
    "    tempgrad = tempfield.gradientFn\n",
    "    valcheck = tempgrad[1].evaluate(swarm)\n",
    "    if valcheck is None:\n",
    "        vals = np.array(0, dtype='float64')\n",
    "    else:\n",
    "        vals = valcheck.sum()*dx\n",
    "    return vals\n",
    "\n",
    "def rms():\n",
    "    return math.sqrt(v2int.evaluate()[0])\n",
    "\n",
    "#This one gets cleaned up when Surface integrals are available\n",
    "def rms_surf(swarm, dx):\n",
    "    rmsmaxfn = fn.math.sqrt(fn.math.dot(velocityField,velocityField))\n",
    "    rmscheck = rmsmaxfn.evaluate(swarm)\n",
    "    if rmscheck is None:\n",
    "        rmsvals = np.array(0, dtype='float64')\n",
    "    else:\n",
    "        rmsvals = rmscheck.sum()*dx\n",
    "    return rmsvals\n",
    "\n",
    "def max_vx_surf(velfield, swarm):\n",
    "    surfvelxmaxfn = fn.view.min_max(velfield[0])\n",
    "    surfvelxmaxfn.evaluate(swarm)\n",
    "    return surfvelxmaxfn.max_global()\n",
    "\n",
    "def max_vy_surf(velfield, swarm):\n",
    "    surfvelxmaxfn = fn.view.min_max(velfield[1])\n",
    "    surfvelxmaxfn.evaluate(swarm)\n",
    "    return surfvelxmaxfn.max_global()\n",
    "\n",
    "def gravwork(workfn):\n",
    "    return workfn.evaluate()[0]\n",
    "\n",
    "def viscdis(vdissfn):\n",
    "    return vdissfn.evaluate()[0]\n",
    "\n",
    "def visc_extr(viscfn):\n",
    "    vuviscfn = fn.view.min_max(viscfn)\n",
    "    vuviscfn.evaluate(linearMesh)\n",
    "    return vuviscfn.max_global(), vuviscfn.min_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fields for saving data / fields\n",
    "\n",
    "rmsField = uw.fevariable.FeVariable( feMesh=linearMesh,   nodeDofCount=1)\n",
    "rmsfn = fn.math.sqrt(fn.math.dot(velocityField,velocityField))\n",
    "rmsdata = rmsfn.evaluate(linearMesh)\n",
    "rmsField.data[:] = rmsdata \n",
    "\n",
    "viscField = uw.fevariable.FeVariable( feMesh=linearMesh,   nodeDofCount=1)\n",
    "viscdata = mantleviscosityFn.evaluate(linearMesh)\n",
    "viscField.data[:] = viscdata\n",
    "\n",
    "\n",
    "strainrateField = uw.fevariable.FeVariable( feMesh=linearMesh,   nodeDofCount=1)\n",
    "srtdata = fn.tensor.second_invariant( \n",
    "                    fn.tensor.symmetric( \n",
    "                        velocityField.gradientFn ))\n",
    "rostfield = srtdata.evaluate(linearMesh)\n",
    "strainrateField.data[:] = rostfield\n",
    "\n",
    "viscVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<glucifer._glucifer.Figure at 0x10d676b50>"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Images\n",
    "figEta = glucifer.Figure()\n",
    "figEta + glucifer.objects.Points(gSwarm,viscVariable, logScale=True)\n",
    "\n",
    "\n",
    "figMat = glucifer.Figure()\n",
    "figMat + glucifer.objects.Points(gSwarm,materialVariable, colours='brown white blue red')\n",
    "figMat + glucifer.objects.Mesh(linearMesh)\n",
    "\n",
    "\n",
    "figStrainRate = glucifer.Figure()\n",
    "figStrainRate + glucifer.objects.Surface(elementMesh, secinvCopy, logScale=True)\n",
    "\n",
    "\n",
    "figVelocityMag = glucifer.Figure()\n",
    "figVelocityMag + glucifer.objects.Surface(elementMesh, fn.math.dot(velocityField,velocityField))\n",
    "\n",
    "figTemp = glucifer.Figure()\n",
    "figTemp + glucifer.objects.Surface(elementMesh, temperatureField)\n",
    "\n",
    "\n",
    "\n",
    "#Pack some stuff into a database as well\n",
    "figDb = glucifer.Figure()\n",
    "figDb + glucifer.objects.Points(gSwarm,viscVariable, logScale=True, colours='brown white blue')\n",
    "figDb + glucifer.objects.Points(gSwarm,materialVariable, colours='brown black white blue')\n",
    "figDb + glucifer.objects.Mesh(linearMesh)\n",
    "figDb + glucifer.objects.VectorArrows(elementMesh,velocityField, arrowHead=0.2, scaling=0.0002)\n",
    "figDb + glucifer.objects.Surface(elementMesh, secinvCopy, logScale=True, colours='brown white blue')\n",
    "                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main simulation loop\n",
    "=======\n",
    "\n",
    "The main time stepping loop begins here. Before this the time and timestep are initialised to zero and the output statistics arrays are set up. Also the frequency of outputting basic statistics to the screen is set in steps_output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pics = uw.swarm.PICIntegrationSwarm(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "steps_end = 5\n",
    "steps_display_info = 20\n",
    "swarm_update = 15\n",
    "swarm_repop = 30\n",
    "files_output = 100\n",
    "gldbs_output = 25\n",
    "images_output = 100\n",
    "checkpoint_every = 25\n",
    "metric_output = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkpoint1(step, checkpointPath,filename, filewrites):\n",
    "    path = checkpointPath + str(step) \n",
    "    velfile = \"velocityField\" + \".hdf5\"\n",
    "    tempfile = \"temperatureField\" + \".hdf5\"\n",
    "    pressfile = \"pressureField\" + \".hdf5\"\n",
    "    swarmfile = \"materialSwarm\" + \".hdf5\"\n",
    "    os.mkdir(path)\n",
    "    ##Write and save the file, if not already a writing step\n",
    "    if not step % filewrites == 0:\n",
    "        filename.write((13*'%-15s ' + '\\n') % (realtime, Viscdis, float(Nu0glob), float(Nu1glob), Avg_temp, \n",
    "                                              Rms,Rmsurfglob,Max_vx_surf,Gravwork, etamax, etamin, Viscdisair, Viscdislith))\n",
    "    filename.close()\n",
    "    shutil.copyfile(os.path.join(outputPath, outputFile), os.path.join(path, outputFile))\n",
    "\n",
    "\n",
    "def checkpoint2(step, checkpointPath, swarm, filename, varlist = [materialVariable], varnames = ['materialVariable']):\n",
    "    path = checkpointPath + str(step) \n",
    "    velfile = \"velocityField\" + \".hdf5\"\n",
    "    tempfile = \"temperatureField\" + \".hdf5\"\n",
    "    pressfile = \"pressureField\" + \".hdf5\"\n",
    "    velocityField.save(os.path.join(path, velfile))\n",
    "    temperatureField.save(os.path.join(path, tempfile))\n",
    "    pressureField.save(os.path.join(path, pressfile))\n",
    "    swarm.save(os.path.join(path, \"swarm.h5\") ) \n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.save(os.path.join(path,varnames[ix] + \".h5\"), swarmfilepath=os.path.join(path, \"swarm.h5\"))\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step = 0\n",
    "#f_o = open(outputPath+outputFile, 'w')\n",
    "#checkpoint1(step, checkpointPath,f_o, metric_output)           \n",
    "#checkpoint2(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "#varlist = [materialVariable, rockIntVar, airIntVar, lithIntVar]\n",
    "#path = checkpointPath + str(step) \n",
    "#materialVariable.save(os.path.join(path,varnames[0] + \".h5\"), swarmfilepath=os.path.join(path, \"swarm.h5\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#step = int(checkpointLoadDir.split('/')[-1])\n",
    "#step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.9746865359641632e-07, 1.0631466044131293e-07)"
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "advector.get_max_dt(), advDiff.get_max_dt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "start = time.clock()\n",
    "# setup summary output file (name above)\n",
    "if checkpointLoad:\n",
    "    if uw.rank() == 0:\n",
    "        shutil.copyfile(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    comm.Barrier()\n",
    "    #os.rename(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "    prevdata = np.genfromtxt(os.path.join(outputPath, outputFile), skip_header=0, skip_footer=0)\n",
    "    realtime = prevdata[prevdata.shape[0]-1, 0]\n",
    "    step = int(checkpointLoadDir.split('/')[-1])\n",
    "    timevals = [0.]\n",
    "else:\n",
    "    f_o = open(outputPath+outputFile, 'w')\n",
    "    realtime = 0.\n",
    "    step = 0\n",
    "    timevals = [0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9.43954215108e-09\n",
      "1.88790843022e-08\n",
      "3.77581686043e-08\n",
      "7.55163372086e-08\n",
      "1.51032674417e-07\n"
     ]
    }
   ],
   "source": [
    "ts = ((D*1e3)**2)/k\n",
    "secperyear = (3600*24*365)\n",
    "times = [2500., 5000., 10000., 20000., 40000.]\n",
    "for t in times:\n",
    "    dt = t/(ts/secperyear)\n",
    "    print dt\n",
    "    \n",
    "dtdefault = DEFAULTDT/(ts/secperyear)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "I/O operation on closed file",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-331-97fa1d5a39fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0muw\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrank\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             f_o.write((13*'%-15s ' + '\\n') % (realtime, Viscdis, float(Nu0glob), float(Nu1glob), Avg_temp, \n\u001b[0;32m---> 52\u001b[0;31m                                               Rms,Rmsurfglob,Max_vx_surf,Gravwork, etamax, etamin, Viscdisair, Viscdislith))\n\u001b[0m\u001b[1;32m     53\u001b[0m     \u001b[0;31m#if step %  steps_display_info == 0:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;31m# output image to file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: I/O operation on closed file"
     ]
    }
   ],
   "source": [
    "\n",
    "# Perform steps\n",
    "while realtime < 3.77581686043e-06: #about 1 my scaled\n",
    "#while step < 5:\n",
    "    #Enter non-linear loop\n",
    "    print step\n",
    "    solver.solve(nonLinearIterate=True)\n",
    "    dt = dtdefault\n",
    "    if step == 0:\n",
    "        dt = 0.\n",
    "    advDiff.integrate(dt)\n",
    "    # Advect swarm using this timestep size\n",
    "    advector.integrate(dt)\n",
    "    # Increment\n",
    "    realtime += dt\n",
    "    step += 1\n",
    "    timevals.append(realtime)\n",
    "    #Update any swarm variables and temperature field in the air region\n",
    "    tempVariable.data[:] = temperatureField.evaluate(gSwarm)[:]\n",
    "    for index, coord in enumerate(linearMesh.data):\n",
    "        if coord[1] >= 1.:\n",
    "            temperatureField.data[index] = 0.   \n",
    "    # Calculate the Metrics, only on 1 of the processors:\n",
    "    if (step % metric_output == 0):\n",
    "        tempVariable.data[:] = temperatureField.evaluate(gSwarm)[:]\n",
    "        Avg_temp = avg_temp()\n",
    "        Rms = rms()\n",
    "        Max_vx_surf = max_vx_surf(velocityField, surfintswarm)\n",
    "        Gravwork = gravwork(dwint)\n",
    "        Viscdis = viscdis(vdint)\n",
    "        Viscdisair = viscdis(vdintair)\n",
    "        Viscdislith = viscdis(vdintlith)\n",
    "        etamax, etamin = visc_extr(mantleviscosityFn)\n",
    "        #These are the ones that need mpi4py treatment\n",
    "        Nu0loc = nusselt(temperatureField, baseintswarm, dx)\n",
    "        Nu1loc = nusselt(temperatureField, surfintswarm, dx)\n",
    "        Rmsurfloc = rms_surf(surfintswarm, dx)\n",
    "        #Setup the global output arrays\n",
    "        dTp = Nu0loc.dtype\n",
    "        Nu0glob = np.array(0, dtype=dTp)\n",
    "        dTp = Nu1loc.dtype\n",
    "        Nu1glob = np.array(0, dtype=dTp)\n",
    "        dTp = Rmsurfloc.dtype\n",
    "        Rmsurfglob = np.array(0, dtype=dTp)\n",
    "        #Do global sum\n",
    "        comm.Allreduce(Nu0loc, Nu0glob, op=MPI.SUM)\n",
    "        comm.Allreduce(Nu1loc, Nu1glob, op=MPI.SUM)\n",
    "        comm.Allreduce(Rmsurfloc, Rmsurfglob, op=MPI.SUM)\n",
    "        # output to summary text file\n",
    "        if uw.rank()==0:\n",
    "            f_o.write((13*'%-15s ' + '\\n') % (realtime, Viscdis, float(Nu0glob), float(Nu1glob), Avg_temp, \n",
    "                                              Rms,Rmsurfglob,Max_vx_surf,Gravwork, etamax, etamin, Viscdisair, Viscdislith))\n",
    "    #if step %  steps_display_info == 0:\n",
    "    # output image to file\n",
    "    if (step % files_output == 0) & (writeFiles == True):\n",
    "        ##Files to save\n",
    "        fnametemp = \"temperatureField\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".hdf5\"\n",
    "        fullpath = os.path.join(outputPath + \"files/\" + fnametemp)\n",
    "        temperatureField.save(fullpath)\n",
    "        #RMS\n",
    "        fnamerms = \"rmsField\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".hdf5\"\n",
    "        fullpath = os.path.join(outputPath + \"files/\" + fnamerms)\n",
    "        rmsField.save(fullpath)\n",
    "        #Strain rate invariant\n",
    "        fnamestrainrate = \"strainrateField\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".hdf5\"\n",
    "        fullpath = os.path.join(outputPath + \"files/\" + fnamestrainrate)\n",
    "        strainrateField.save(fullpath)\n",
    "    if (step % gldbs_output == 0) & (writeFiles == True):\n",
    "        #Rebuild any necessary swarm variables\n",
    "        viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)\n",
    "        #Write gldbs\n",
    "        fnamedb = \"dbFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".gldb\"\n",
    "        fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "        figDb.show()\n",
    "        figDb.save_database(fullpath)\n",
    "    if (step % images_output == 0) & (writeFiles == True):\n",
    "        #Rebuild any necessary swarm variables\n",
    "        viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)\n",
    "        #Write gldbs\n",
    "        iname1 = \"viscFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".png\"\n",
    "        fullpath1 = os.path.join(outputPath + \"images/\" + iname1)\n",
    "        iname2 = \"matFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".png\"\n",
    "        fullpath2 = os.path.join(outputPath + \"images/\" + iname2)\n",
    "        iname3 = \"stFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".png\"\n",
    "        fullpath3 = os.path.join(outputPath + \"images/\" + iname3)\n",
    "        iname4 = \"v2Fig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".png\"\n",
    "        fullpath4 = os.path.join(outputPath + \"images/\" + iname4)\n",
    "        iname5 = \"tempFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".png\"\n",
    "        fullpath5 = os.path.join(outputPath + \"images/\" + iname5)\n",
    "        #\n",
    "        #figEta.show()\n",
    "        #figEta.save_image(fullpath1)\n",
    "        #figMat.show()\n",
    "        #figMat.save_image(fullpath2)\n",
    "        #figStrainRate.show()\n",
    "        #figStrainRate.save_image(fullpath3)\n",
    "        #figVelocityMag.show()\n",
    "        #figVelocityMag.save_image(fullpath4)\n",
    "        #figTemp.show()\n",
    "        #figTemp.save_image(fullpath5)\n",
    "        \n",
    "    ################\n",
    "    #Particle update\n",
    "    ###############\n",
    "    particledepths = 1. - gSwarm.particleCoordinates.data[:,1]\n",
    "    particletemps = temperatureField.evaluate(gSwarm)[:,0]\n",
    "    conditionmap['depthcondition']['data'] = particledepths\n",
    "    conditionmap['avgtempcondition']['data'] = particletemps\n",
    "    if step % swarm_update == 0:\n",
    "        number_updated = 0\n",
    "        for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "            check = update_swarm(DG, particleID)\n",
    "            if check > -1:\n",
    "                number_updated += 1\n",
    "                #if check == 0:\n",
    "                #    print \"from \" + str(materialVariable.data[particleID]) + \" to \" + str(check)\n",
    "                materialVariable.data[particleID] = check\n",
    "            else:\n",
    "                pass\n",
    "        print number_updated \n",
    "        #Also update those integration swarms\n",
    "        rockIntVar.data[:] = 0.\n",
    "        notair = np.where(materialVariable.data != airIndex)\n",
    "        rockIntVar.data[notair] = 1.\n",
    "        airIntVar.data[:] = 0.\n",
    "        notrock = np.where(materialVariable.data == airIndex)\n",
    "        airIntVar.data[notrock] = 1.\n",
    "        lithIntVar.data[:] = 0.\n",
    "        islith = np.where((materialVariable.data == lithosphereIndex) | (materialVariable.data == crustIndex))\n",
    "        lithIntVar.data[islith] = 1.\n",
    "    #Also repopulate\n",
    "    if step % swarm_repop == 0:\n",
    "        pics.repopulate()\n",
    "        \n",
    "    if step % checkpoint_every == 0:\n",
    "        if uw.rank() == 0:\n",
    "            checkpoint1(step, checkpointPath,f_o, metric_output)           \n",
    "        checkpoint2(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "        f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "\n",
    "        \n",
    "        \n",
    "#checkpoint(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "f_o.close()\n",
    "#checkpoint(step, checkpointPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'start' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-dc3c2f2e7c24>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmachine_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"total time is: \"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmachine_time\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'start' is not defined"
     ]
    }
   ],
   "source": [
    "machine_time = (time.clock()-start)\n",
    "print(\"total time is: \" + str(machine_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
