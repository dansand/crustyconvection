{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Crameri-Tackley (2015) model\n",
    "======="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "#import matplotlib.pyplot as pyplot\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import collections\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Import the mesh refinement functions\n",
    "import spmesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model name.  \n",
    "############\n",
    "Model = \"T\"\n",
    "ModNum = 0\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModIt = \"Base\"\n",
    "elif sys.argv[1] == '-f':\n",
    "    ModIt = \"Base\"\n",
    "else:\n",
    "    ModIt = str(sys.argv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set physical constants and parameters, including the Rayleigh number (*RA*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Physical parameters\n",
    "###########\n",
    "\n",
    "\n",
    "#dimensional parameter dictionary\n",
    "dp = edict({'LS':2890.*1e3,\n",
    "           'rho':3300,\n",
    "           'g':9.81, \n",
    "           'eta0':1e23,\n",
    "           'k':10**-6,\n",
    "           'a':1.25*10**-5, \n",
    "           'TS':300.,\n",
    "           'TB':2800.,\n",
    "           'deltaT':2500., \n",
    "           'cohesion':1e7, \n",
    "           'E':240000., \n",
    "           'R':8.314,\n",
    "           'V':6.34*(10**-7),\n",
    "           'StALS': 145e3})\n",
    "\n",
    "#non-dimensional parameter dictionary\n",
    "RAfac = 1.\n",
    "ndp = edict({'RA':1e6*RAfac,      \n",
    "              'LS':1.,\n",
    "              'eta0':1.,\n",
    "              'StAeta0':1e-3,\n",
    "              'k':1.,\n",
    "              'E':11.55,\n",
    "              'V':3.0,\n",
    "              'H':20.,\n",
    "              'TR':(1600./2500.),\n",
    "              'TS':(dp.TS/2500.),\n",
    "              'RD':1.,\n",
    "              'cohesion':1577.*RAfac,\n",
    "              'cohesion_reduce':10.,\n",
    "              'fc':0.1, \n",
    "              'low_visc':RAfac*5e-4,\n",
    "              'up_visc':5e4,\n",
    "              'random_temp': 0.05})\n",
    "\n",
    "\n",
    "\n",
    "#A few extra parameters defining lengths scales, mainly effects materal transistions etc.\n",
    "MANTLETOCRUST = (27.*1e3)/dp.LS #Crust depth\n",
    "CRUSTTOMANTLE = (300.*1e3)/dp.LS \n",
    "LITHTOMANTLE = (660.*1e3)/dp.LS \n",
    "MANTLETOLITH = (200.*1e3)/dp.LS \n",
    "TOPOHEIGHT = (20.*1e3)/dp.LS  #rock-air topography limits\n",
    "AVGTEMP = 0.53 #Used to define lithosphere\n",
    "\n",
    "\n",
    "#Compositional Rayliegh number of rock-air\n",
    "ETAREF = dp.rho*dp.g*dp.a*dp.deltaT*((dp.LS)**3)/(ndp.RA*dp.k) #equivalent dimensional reference viscosity\n",
    "RC = (3300.*dp.g*(dp.LS)**3)/(ETAREF *dp.k) #Composisitional Rayleigh number for rock-air buoyancy force\n",
    "COMP_RA_FACT = RC/ndp.RA\n",
    "#Additional dimensionless paramters\n",
    "ndp[\"StA\"] = ndp.RA*COMP_RA_FACT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model / mesh / solver setup parameters\n",
    "###########\n",
    "stickyAir = True\n",
    "\n",
    "#Domain STUFF\n",
    "MINX = -1.\n",
    "MINY = 0.\n",
    "MAXX = 1.0\n",
    "MAXY = 1.\n",
    "if MINX == 0.:\n",
    "    squareModel = True\n",
    "else: \n",
    "    squareModel = False\n",
    "    \n",
    "#MESH STUFF\n",
    "RES = 96\n",
    "dim = 2          # number of spatial dimensions\n",
    "if MINX == 0.:\n",
    "    Xres = RES\n",
    "else:\n",
    "    Xres = 2*RES\n",
    "if stickyAir:\n",
    "    Yres = RES\n",
    "    MAXY = 1. + dp.StALS/dp.LS #150km\n",
    "else:\n",
    "    Yres = RES\n",
    "    MAXY = 1.\n",
    "\n",
    "periodic = [False, False]\n",
    "elementType = \"Q1/dQ0\"\n",
    "#elementType =\"Q2/DPC1\"\n",
    "refineMesh = True\n",
    "\n",
    "#System/Solver stuff\n",
    "PIC_integration=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model Runtime parameters\n",
    "###########\n",
    "\n",
    "swarm_update = 25\n",
    "swarm_repop = 25\n",
    "files_output = 1e6\n",
    "gldbs_output = 25\n",
    "images_output = 1e6\n",
    "checkpoint_every = 25\n",
    "metric_output = 25\n",
    "sticky_air_temp = 10\n",
    "\n",
    "comm.Barrier() #Barrier here so no procs run the check in the next cell too early \n",
    "\n",
    "assert metric_output <= checkpoint_every, 'Checkpointing should run less or as ofen as metric output'\n",
    "assert (metric_output >= swarm_update), 'Swarm update is needed before checkpointing'\n",
    "assert metric_output >= sticky_air_temp, 'Sticky air temp should be updated more frequently that metrics'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## build and Refine mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (\"Q1/dQ0\"),\n",
    "                                 elementRes  = (Xres, Yres), \n",
    "                                 minCoord    = (MINX,MINY), \n",
    "                                 maxCoord=(MAXX,MAXY), periodic=periodic)\n",
    "\n",
    "\n",
    "\n",
    "velocityField       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=dim )\n",
    "pressureField       = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "temperatureField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "temperatureDotField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min\n",
      "(192, 0.0062500000000000888, 1.7000000000000011, 0.60000000000001708)\n",
      "('edges', 192)\n",
      "-- iteration 0 --\n",
      "| F( p_n ) |^2: 3.54456018519e-05\n",
      "| p_n+1 - p_n |^2: 1.02511115934\n",
      "-- iteration 1 --\n",
      "| F( p_n ) |^2: 7.03339083261e-31\n",
      "Min, Max element width: \n",
      "0.00625\n",
      "0.01458\n"
     ]
    }
   ],
   "source": [
    "#X-Axis\n",
    "\n",
    "if refineMesh:\n",
    "    mesh.reset()\n",
    "    axis = 0\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (abs(mesh.maxCoord[axis]) - abs(mesh.minCoord[axis]))/2.\n",
    "    el_reduction = 0.6\n",
    "    dx = mesh.maxCoord[axis] - min_point\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction) *deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    deform_1d(deform_lengths, mesh,axis = 'x',norm = 'Min', constraints = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axis = 1\n",
    "orgs = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "\n",
    "value_to_constrain = 1.\n",
    "\n",
    "\n",
    "yconst = [(find_closest(orgs, value_to_constrain), np.array([value_to_constrain,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min\n",
      "(96, 0.0065635813148788441, 0.88991223327566316, 0.61684210526314709)\n",
      "('edges', 96)\n",
      "-- iteration 0 --\n",
      "| F( p_n ) |^2: 0.000161872397845\n",
      "| p_n+1 - p_n |^2: 0.468108300329\n",
      "-- iteration 1 --\n",
      "| F( p_n ) |^2: 2.28582054321e-05\n",
      "| p_n+1 - p_n |^2: 1.76834906235e-28\n",
      "Min, Max element width: \n",
      "0.00684\n",
      "0.01513\n"
     ]
    }
   ],
   "source": [
    "#Y-Axis\n",
    "if refineMesh:\n",
    "    #Y-Axis\n",
    "    axis = 1\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (mesh.maxCoord[axis])\n",
    "    el_reduction = 0.6\n",
    "    dx = mesh.maxCoord[axis]\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction)*deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    deform_1d(deform_lengths, mesh,axis = 'y',norm = 'Min', constraints = yconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src='data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAABLAAAAJYCAIAAAD9hIhNAAAcl0lEQVR42u3dwZJltY4FUF2C///lZGZMMDBUSq6UtdaoG+oQ8U6cfu3NtbY+X19fAQAAwDx/eAUAAAACIQAAAAIhAAAAAiEAAAACIQAAAAIhAAAAAiEAAAACIQAAAAIhAAAAAiEAAAACIQAAAAIhAAAAAiEAAAACIQAAAAIhAAAAAiEAAAACIQAAAAIhAAAAAiEAAAACIQAAAAIhAAAAAiEAAAACIQAAAAIhAACAQAgAAIBACAAAgEAIAACAQAgAAIBACAAAgEAIAACAQAgAAEAvf3oFy+fz8RIAAOB5X19fXoJA+F+/jM/n8++//s2/WPSP/Y1/8Xf9A3/5j/2EB6/9lTv/kPQ/8M0//xP+15Q/+f2/9Qt/rPR/LvoD//fvpvxDcv9zpT9Y+kj13yr6v7XL/82T/udT/hv+h///rMS/Uv1g+omo6Znt8ik0658g+CyujAIAAAiEAAAACIQAAAA872Oe8u934TIxAAAMIAQtSmXOX4ZSGaUyRQ8qlVEqo1RGqUwolVEqo1RGqUzzM9vlU2golcnmyigAAIBACAAAgEAIAADA85TKbO/CZWIAABhACFqUypy/DKUySmWKHlQqo1RGqYxSmVAqo1RGqYxSmeZntsun0FAqk82VUQAAAIEQAAAAgRAAAIDnKZXZ3oXLxAAAMIAQtCiVOX8ZSmWUyhQ9qFRGqYxSGaUyoVRGqYxSGaUyzc9sl0+hoVQmmyujAAAAAiEAAAACIQAAAM9TKrO9C5eJAQBgACFoUSpz/jKUyiiVKXpQqYxSGaUySmVCqYxSGaUySmWan9kun0JDqUw2V0YBAAAEQgAAAARCAAAAnqdUZnsXLhMDAMAAQtCiVOb8ZSiVUSpT9KBSGaUySmWUyoRSGaUySmWUyjQ/s10+hYZSmWyujAIAAAiEAAAATGKGcHsXfjsGAIABhKDFDOH5yzBDaIaw6EEzhGYIzRCaIQwzhGYIzRCaIWx+Zrt8Cg0zhNlcGQUAABjKldHtXfhXBQAAMIAQtLgyev4yXBl1ZbToQVdGXRl1ZdSV0XBl1JVRV0ZdGW1+Zrt8Cg1XRrO5MgoAACAQAgAAMIkZwu1d+O0YAAAGEIIWM4TnL8MMoRnCogfNEJohNENohjDMEJohNENohrD5me3yKTTMEGZzZRQAAGAoV0a3d+FfFQAAwABC0OLK6PnLcGXUldGiB10ZdWXUlVFXRsOVUVdGXRl1ZbT5me3yKTRcGc3myigAAIBACAAAwCRmCLd34bdjAAAYQAhazBCevwwzhGYIix40Q2iG0AyhGcIwQ2iG0AyhGcLmZ7bLp9AwQ5jNlVEAAACBEAAAgEnMEG7vwm/HAAAwgBC0mCE8fxlmCM0QFj1ohtAMoRlCM4RhhtAMoRlCM4TNz2yXT6FhhjCbK6MAAAACIQAAAJOYIdzehd+OAQBgACFoMUN4/jLMEJohLHrQDKEZQjOEZgjDDKEZQjOEZgibn9kun0LDDGE2V0YBAACGcmV0exf+VQEAAAwgBC2ujJ6/DFdGXRktetCVUVdGXRl1ZTRcGXVl1JVRV0abn9kun0LDldFsrowCAAAIhAAAAExihnB7F347BgCAAYSgxQzh+cswQ2iGsOhBM4RmCM0QmiEMM4RmCM0QmiFsfma7fAoNM4TZXBkFAAAQCAEAAJjEDOH2Lvx2DAAAAwhBixnC85dhhtAMYdGDZgjNEJohNEMYZgjNEJohNEPY/Mx2+RQaZgizuTIKAAAgEAIAADCJGcLtXfjtGAAABhCCFjOE5y/DDKEZwqIHzRCaITRDaIYwzBCaITRDaIaw+Znt8ik0zBBmc2UUAABAIAQAAGASM4Tbu/DbMQAADCAELWYIz1+GGUIzhEUPmiE0Q2iG0AxhmCE0Q2iG0Axh8zPb5VNomCHM5sooAACAQAgAAMAkZgi3d+G3YwAAGEAIWswQnr8MM4RmCIseNENohtAMoRnCMENohtAMoRnC5me2y6fQMEOYzZVRAAAAgRAAAIBJzBBu78JvxwAAMIAQtJghPH8ZZgjNEBY9aIbQDKEZQjOEYYbQDKEZQjOEzc9sl0+hYYYwmyujAAAAAiEAAACTmCHc3oXfjgEAYAAhaDFDeP4yzBCaISx60AyhGUIzhGYIwwyhGUIzhGYIm5/ZLp9CwwxhNldGAQAABEIAAAAEQgAAAJ6nVGZ7Fy4TAwDAAELQolTm/GUolVEqU/SgUhmlMkpllMqEUhmlMkpllMo0P7NdPoWGUplsrowCAAAIhAAAAExihnB7F347BgCAAYSgxQzh+cswQ2iGsOhBM4RmCM0QmiEMM4RmCM0QmiFsfma7fAoNM4TZXBkFAAAQCAEAAJjEDOH2Lvx2DAAAAwhBixnC85dhhtAMYdGDZgjNEJohNEMYZgjNEJohNEPY/Mx2+RQaZgizuTIKAAAgEAIAACAQAgAA8DylMtu7cJkYAAAGEIIWpTLnL0OpjFKZogeVyiiVUSqjVCaUyiiVUSqjVKb5me3yKTSUymRzZRQAAEAgBAAAYBIzhNu78NsxAAAMIAQtZgjPX4YZQjOERQ+aITRDaIbQDGGYITRDaIbQDGHzM9vlU2iYIczmyigAAIBACAAAwCRmCLd34bdjAAAYQAhazBCevwwzhGYIix40Q2iG0AyhGcIwQ2iG0AyhGcLmZ7bLp9AwQ5jNlVEAAACBEAAAAIEQAACA5ymV2d6Fy8QAADCAELQolTl/GUpllMoUPahURqmMUhmlMqFURqmMUhmlMs3PbJdPoaFUJpsrowAAAAIhAAAAk5gh3N6F344BAGAAIWgxQ3j+MswQmiEsetAMoRlCM4RmCMMMoRlCM4RmCJuf2S6fQsMMYTZXRgEAAARCAAAABEIAAACep1RmexcuEwMAwABC0KJU5vxlKJVRKlP0oFIZpTJKZZTKhFIZpTJKZZTKND+zXT6FhlKZbK6MAgAACIQAAAAIhAAAADxPqcz2LlwmBgCAAYSgRanM+ctQKqNUpuhBpTJKZZTKKJUJpTJKZZTKKJVpfma7fAoNpTLZXBkFAAAQCAEAAJjEDOH2Lvx2DAAAAwhBixnC85dhhtAMYdGDZgjNEJohNEMYZgjNEJohNEPY/Mx2+RQaZgizuTIKAAAgEAIAACAQAgAA8DylMtu7cJkYAAAGEIIWpTLnL0OpjFKZogeVyiiVUSqjVCaUyiiVUSqjVKb5me3yKTSUymRzZRQAAEAgBAAAQCAEAADgeUpltnfhMjEAAAwgBC1KZc5fhlIZpTJFDyqVUSqjVEapTCiVUSqjVEapTPMz2+VTaCiVyebKKAAAgEAIAADAJGYIt3fht2MAABhACFrMEJ6/DDOEZgiLHjRDaIbQDKEZwjBDaIbQDKEZwuZntsun0DBDmM2VUQAAAIEQAAAAgRAAAIDnKZXZ3oXLxAAAMIAQtCiVOX8ZSmWUyhQ9qFRGqYxSGaUyoVRGqYxSGaUyzc9sl0+hoVQmmyujAAAAAiEAAAACIQAAAM9TKrO9C5eJAQBgACFoUSpz/jKUyiiVKXpQqYxSGaUySmVCqYxSGaUySmWan9kun0JDqUw2V0YBAAAEQgAAAARCAAAAnqdUZnsXLhMDAMAAQtCiVOb8ZSiVUSpT9KBSGaUySmWUyoRSGaUySmWUyjQ/s10+hYZSmWyujAIAAAiEAAAACIQAAAA8T6nM9i5cJgYAgAGEoEWpzPnLUCqjVKboQaUySmWUyiiVCaUySmWUyiiVaX5mu3wKDaUy2VwZBQAAEAgBAAAQCAEAAHieUpntXbhMDAAAAwhBi1KZ85ehVEapTNGDSmWUyiiVUSoTSmWUyiiVUSrT/Mx2+RQaSmWyuTIKAAAgEAIAACAQAgAA8DylMtu7cJkYAAAGEIIWpTLnL0OpjFKZogeVyiiVUSqjVCaUyiiVUSqjVKb5me3yKTSUymRzZRQAAEAgBAAAQCAEAADgeUpltnfhMjEAAAwgBC1KZc5fhlIZpTJFDyqVUSqjVEapTCiVUSqjVEapTPMz2+VTaCiVyebKKAAAgEAIAACAQAgAAIBACAAAwJu0jG7vwnQpAAAMIAQtWkbPX4aWUS2jRQ9qGdUyqmVUy2hoGdUyqmVUy2jzM9vlU2hoGc3myigAAIBACAAAgEAIAADA85TKbO/CZWIAABhACFqUypy/DKUySmWKHlQqo1RGqYxSmVAqo1RGqYxSmeZntsun0FAqk82VUQAAAIEQAAAAgRAAAIDnKZXZ3oXLxAAAMIAQtCiVOX8ZSmWUyhQ9qFRGqYxSGaUyoVRGqYxSGaUyzc9sl0+hoVQmmyujAAAAAiEAAAACIQAAAM9TKrO9C5eJAQBgACFoUSpz/jKUyiiVKXpQqYxSGaUySmVCqYxSGaUySmWan9kun0JDqUw2V0YBAAAEQgAAAARCAAAABEIAAADepGV0exemSwEAYAAhaNEyev4ytIxqGS16UMuollEto1pGQ8uollEto1pGm5/ZLp9CQ8toNldGAQAABEIAAAAEQgAAAJ6nVGZ7Fy4TAwDAAELQolTm/GUolVEqU/SgUhmlMkpllMqEUhmlMkpllMo0P7NdPoWGUplsrowCAAAIhAAAAAiEAAAACIQAAAC8Scvo9i5MlwIAwABC0KJl9PxlaBnVMlr0oJZRLaNaRrWMhpZRLaNaRrWMNj+zXT6FhpbRbK6MAgAACIQAAAAIhAAAADxPqcz2LlwmBgCAAYSgRanM+ctQKqNUpuhBpTJKZZTKKJUJpTJKZZTKKJVpfma7fAoNpTLZXBkFAAAQCAEAABAIAQAAEAgBAAB4k5bR7V2YLgUAgAGEoEXL6PnL0DKqZbToQS2jWka1jGoZDS2jWka1jGoZbX5mu3wKDS2j2VwZBQAAEAgBAAAQCAEAAHieUpntXbhMDAAAAwhBi1KZ85ehVEapTNGDSmWUyiiVUSoTSmWUyiiVUSrT/Mx2+RQaSmWyuTIKAAAgEAIAACAQAgAAIBACAADwJi2j27swXQoAAAMIQYuW0fOXoWVUy2jRg1pGtYxqGdUyGlpGtYxqGdUy2vzMdvkUGlpGs7kyCgAAIBACAAAgEAIAACAQAgAA8CYto9u7MF0KAAADCEGLltHzl6FlVMto0YNaRrWMahnVMhpaRrWMahnVMtr8zHb5FBpaRrO5MgoAACAQAgAAIBACAAAgEAIAAPAmLaPbuzBdCgAAAwhBi5bR85ehZVTLaNGDWka1jGoZ1TIaWka1jGoZ1TLa/Mx2+RQaWkazuTIKAAAgEAIAACAQAgAA8DylMtu7cJkYAAAGEIIWpTLnL0OpjFKZogeVyiiVUSqjVCaUyiiVUSqjVKb5me3yKTSUymRzZRQAAEAgBAAAQCAEAABAIAQAAOBNWka3d2G6FAAABhCCFi2j5y9Dy6iW0aIHtYxqGdUyqmU0tIxqGdUyqmW0+Znt8ik0tIxmc2UUAABAIAQAAEAgBAAAQCAEAADgTVpGt3dhuhQAAAYQghYto+cvQ8uoltGiB7WMahnVMqplNLSMahnVMqpltPmZ7fIpNLSMZnNlFAAAQCAEAABAIAQAAEAgBAAA4E1aRrd3YboUAAAGEIIWLaPnL0PLqJbRoge1jGoZ1TKqZTS0jGoZ1TKqZbT5me3yKTS0jGZzZRQAAEAgBAAAQCAEAABAIAQAAOBNWka3d2G6FAAABhCCFi2j5y9Dy6iW0aIHtYxqGdUyqmU0tIxqGdUyqmW0+Znt8ik0tIxmc2UUAABAIAQAAEAgBAAAQCAEAADgTVpGt3dhuhQAAAYQghYto+cvQ8uoltGiB7WMahnVMqplNLSMahnVMqpltPmZ7fIpNLSMZnNlFAAAQCAEAABAIAQAAEAgBAAA4E1aRrd3YboUAAAGEIIWLaPnL0PLqJbRoge1jGoZ1TKqZTS0jGoZ1TKqZbT5me3yKTS0jGZzZRQAAEAgBAAAQCAEAABAIAQAAOBNWka3d2G6FAAABhCCFi2j5y9Dy6iW0aIHtYxqGdUyqmU0tIxqGdUyqmW0+Znt8ik0tIxmc2UUAABAIAQAAEAgBAAAQCAEAADgTVpGt3dhuhQAAAYQghYto+cvQ8uoltGiB7WMahnVMqplNLSMahnVMqpltPmZ7fIpNLSMZnNlFAAAQCAEAABAIAQAAEAgBAAAQCAEAADgIdZObO9C3RAAAAwgBC3WTpy/DGsnrJ0oetDaCWsnrJ2wdiKsnbB2wtoJayean9kun0LD2olsrowCAAAIhAAAAAiEAAAACIQAAAC8Scvo9i5MlwIAwABC0KJl9PxlaBnVMlr0oJZRLaNaRrWMhpZRLaNaRrWMNj+zXT6FhpbRbK6MAgAACIQAAAAIhAAAAAiEAAAAvEnL6PYuTJcCAMAAQtCiZfT8ZWgZ1TJa9KCWUS2jWka1jIaWUS2jWka1jDY/s10+hYaW0WyujAIAAAiEAAAACIQAAAAIhAAAAAiEAAAAPMTaie1dqBsCAIABhKDF2onzl2HthLUTRQ9aO2HthLUT1k6EtRPWTlg7Ye1E8zPb5VNoWDuRzZVRAAAAgRAAAACBEAAAAIEQAACAN2kZ3d6F6VIAABhACFq0jJ6/DC2jWkaLHtQyqmVUy6iW0dAyqmVUy6iW0eZntsun0NAyms2VUQAAAIEQAAAAgRAAAACBEAAAgDdpGd3ehelSAAAYQAhatIyevwwto1pGix7UMqplVMuoltHQMqplVMuoltHmZ7bLp9DQMprNlVEAAACBEAAAAIEQAAAAgRAAAACBEAAAgIdYO7G9C3VDAAAwgBC0WDtx/jKsnbB2ouhBayesnbB2wtqJsHbC2glrJ6ydaH5mu3wKDWsnsrkyCgAAIBACAAAgEAIAACAQAgAA8CYto9u7MF0KAAADCEGLltHzl6FlVMto0YNaRrWMahnVMhpaRrWMahnVMtr8zHb5FBpaRrO5MgoAACAQAgAAIBACAAAgEAIAACAQAgAA8BBrJ7Z3oW4IAAAGEIIWayfOX4a1E9ZOFD1o7YS1E9ZOWDsR1k5YO2HthLUTzc9sl0+hYe1ENldGAQAABEIAAAAEQgAAAARCAAAABEIAAAAeYu3E9i7UDQEAwABC0GLtxPnLsHbC2omiB62dsHbC2glrJ8LaCWsnrJ2wdqL5me3yKTSsncjmyigAAIBACAAAgEAIAACAQAgAAMCbtIxu78J0KQAADCAELVpGz1+GllEto0UPahnVMqplVMtoaBnVMqplVMto8zPb5VNoaBnN5sooAACAQAgAAIBACAAAgEAIAACAQAgAAMBDrJ3Y3oW6IQAAGEAIWqydOH8Z1k5YO1H0oLUT1k5YO2HtRFg7Ye2EtRPWTjQ/s10+hYa1E9lcGQUAABAIAQAAEAgBAAAQCAEAABAIAQAAeIi1E9u7UDcEAAADCEGLtRPnL8PaCWsnih60dsLaCWsnrJ0IayesnbB2wtqJ5me2y6fQsHYimyujAAAAAiEAAAACIQAAAAIhAAAAAiEAAAAPsXZiexfqhgAAYAAhaLF24vxlWDth7UTRg9ZOWDth7YS1E2HthLUT1k5YO9H8zHb5FBrWTmRzZRQAAEAgBAAAQCAEAABAIAQAAEAgBAAA4CHWTmzvQt0QAAAMIAQt1k6cvwxrJ6ydKHrQ2glrJ6ydsHYirJ2wdsLaCWsnmp/ZLp9Cw9qJbK6MAgAACIQAAAAIhAAAAAiEAAAACIQAAAA8xNqJ7V2oGwIAgAGEoMXaifOXYe2EtRNFD1o7Ye2EtRPWToS1E9ZOWDth7UTzM9vlU2hYO5HNlVEAAACBEAAAAIEQAAAAgRAAAACBEAAAgIdYO7G9C3VDAAAwgBC0WDtx/jKsnbB2ouhBayesnbB2wtqJsHbC2glrJ6ydaH5mu3wKDWsnsrkyCgAAIBACAAAgEAIAACAQAgAAIBACAADwEGsntnehbggAAAYQghZrJ85fhrUT1k4UPWjthLUT1k5YOxHWTlg7Ye2EtRPNz2yXT6Fh7UQ2V0YBAAAEQgAAAARCAAAABEIAAAAEQgAAAB5i7cT2LtQNAQDAAELQYu3E+cuwdsLaiaIHrZ2wdsLaCWsnwtoJayesnbB2ovmZ7fIpNKydyObKKAAAgEAIAACAQAgAAIBACAAAgEAIAADAQ6yd2N6FuiEAABhACFqsnTh/GdZOWDtR9KC1E9ZOWDth7URYO2HthLUT1k40P7NdPoWGtRPZXBkFAAAQCAEAABAIAQAAEAgBAAAQCAEAAHiItRPbu1A3BAAAAwhBi7UT5y/D2glrJ4oetHbC2glrJ6ydCGsnrJ2wdsLaieZntsun0LB2IpsrowAAAAIhAAAAAiEAAAACIQAAAAIhAAAAD7F2YnsX6oYAAGAAIWixduL8ZVg7Ye1E0YPWTlg7Ye2EtRNh7YS1E9ZOWDvR/Mx2+RQa1k5kc2UUAABAIAQAAEAgBAAAQCAEAABAIAQAAOAh1k5s70LdEAAADCAELdZOnL8MayesnSh60NoJayesnbB2IqydsHbC2glrJ5qf2S6fQsPaiWyujAIAAAiEAAAACIQAAAAIhAAAAAiEAAAACIQAAAB0Zw/h9i70zwIAwABC0GIP4fnLsIfQHsKiB+0htIfQHkJ7CMMeQnsI7SG0h7D5me3yKTTsIczmyigAAIBACAAAgEAIAACAQAgAAIBACAAAwEOsndjehbohAAAYQAharJ04fxnWTlg7UfSgtRPWTlg7Ye1EWDth7YS1E9ZOND+zXT6FhrUT2VwZBQAAEAgBAAAQCAEAABAIAQAAEAgBAAB4iLUT27tQNwQAAAMIQYu1E+cvw9oJayeKHrR2wtoJayesnQhrJ6ydsHbC2onmZ7bLp9CwdiKbK6MAAAACIQAAAAIhAAAAAiEAAAACIQAAAAIhAAAA3dlDuL0L/bMAADCAELTYQ3j+MuwhtIew6EF7CO0htIfQHsKwh9AeQnsI7SFsfma7fAoNewizuTIKAAAgEAIAACAQAgAAIBACAAAgEAIAAPAQaye2d6FuCAAABhCCFmsnzl+GtRPWThQ9aO2EtRPWTlg7EdZOWDth7YS1E83PbJdPoWHtRDZXRgEAAARCAAAABEIAAAAEQgAAAARCAAAABEIAAAC6s4dwexf6ZwEAYAAhaLGH8Pxl2ENoD2HRg/YQ2kNoD6E9hGEPoT2E9hDaQ9j8zHb5FBr2EGZzZRQAAEAgBAAAQCAEAABAIAQAAEAgBAAA4CHWTmzvQt0QAAAMIAQt1k6cvwxrJ6ydKHrQ2glrJ6ydsHYirJ2wdsLaCWsnmp/ZLp9Cw9qJbK6MAgAACIQAAAAIhAAAAAiEAAAACIQAAAAIhAAAAHRnD+H2LvTPAgDAAELQYg/h+cuwh9AewqIH7SG0h9AeQnsIwx5CewjtIbSHsPmZ7fIpNOwhzObKKAAAgEAIAACAQAgAAIBACAAAgEAIAACAQAgAAEB39hBu70L/LAAADCAELfYQnr8MewjtISx60B5CewjtIbSHMOwhtIfQHkJ7CJuf2S6fQsMewmyujAIAAAiEAAAACIQAAAAIhAAAAAiEAAAACIQAAAB0Zw/hP1+HCloAAHiaBCQQAgAA4MooAACAQAgAAIBACAAAgEAIAACAQAgAAIBACAAAgEAIAACAQAgAAIBACAAAgEAIAACAQAgAAIBACAAAgEAIAACAQAgAAIBACAAAgEAIAACAQAgAAIBACAAAgEAIAACAQAgAAIBACAAAgEAIAACAQAgAAIBACAAAIBACAAAgEAIAACAQAgAAIBACAAAgEAIAACAQAgAA0NhfgAxZsX6b9O4AAAAASUVORK5CYII='>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "figMesh = glucifer.Figure(figsize=(1200,600),antialias=1)\n",
    "#figMesh.append( glucifer.objects.Mesh(mesh.subMesh, nodeNumbers=True) )\n",
    "figMesh.append( glucifer.objects.Mesh(mesh) )\n",
    "figMesh.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICs and BCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# send boundary condition information to underworld\n",
    "IWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "JWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "TWalls = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "BWalls = mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "AWalls = IWalls + JWalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialise data.. Note that we are also setting boundary conditions here\n",
    "velocityField.data[:] = [0.,0.]\n",
    "pressureField.data[:] = 0.\n",
    "temperatureField.data[:] = 0.\n",
    "temperatureDotField.data[:] = 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create Initial boundary layers, and perturbation (slab)\n",
    "\n",
    "def wbl(x, w0 = 0.06):\n",
    "    delx = 1- abs(x)\n",
    "    Wbl = w0*math.sqrt(delx)\n",
    "    if Wbl== 0.: #to avoid division by zero\n",
    "        Wbl = 1e-8\n",
    "    return Wbl\n",
    "\n",
    "\n",
    "def tempf(z,w,t0=0.64):\n",
    "    temp = t0*math.erf((1-z)/w)\n",
    "    return temp\n",
    "\n",
    "age_asymmetry = 1. #1 meaning no asymmetry\n",
    "\n",
    "for index, coord in enumerate(mesh.data):\n",
    "    if coord[0] > 0.:\n",
    "        w = wbl(coord[0])\n",
    "        t = tempf(coord[1], w)\n",
    "        temperatureField.data[index] = t\n",
    "    else:\n",
    "        w = wbl(coord[0])/age_asymmetry\n",
    "        t = tempf(coord[1], w)\n",
    "        temperatureField.data[index] = t\n",
    "\n",
    "for index, coord in enumerate(mesh.data):\n",
    "    if abs(coord[0]) < wbl(0)/2. and coord[1] > 0.5:\n",
    "        w = wbl(0)/2.\n",
    "        d = w - abs(coord[0])\n",
    "        t = tempf(d, coord[1], w)\n",
    "        temperatureField.data[index] = t\n",
    "               \n",
    "\n",
    "#Set sticky air Temp to zero\n",
    "for index, coord in enumerate(mesh.data):\n",
    "    if coord[1] >= 1.:\n",
    "        temperatureField.data[index] = dp.TS/dp.deltaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now setup the dirichlet boundary condition\n",
    "# Note that through this object, we are flagging to the system \n",
    "# that these nodes are to be considered as boundary conditions. \n",
    "# Also note that we provide a tuple of sets.. One for the Vx, one for Vy.\n",
    "freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = (IWalls, JWalls) )\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(TWalls,) )\n",
    "dT_dy = [0.,0.]\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "neumannTempBC = uw.conditions.NeumannCondition( dT_dy, variable=temperatureField, \n",
    "                                         indexSetsPerDof=BWalls)\n",
    "\n",
    "\n",
    "# set initial conditions (and boundary values)\n",
    "velocityField.data[:] = [0.,0.]\n",
    "pressureField.data[:] = 0.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Add Random 125 K temp perturbation\n",
    "\n",
    "tempNump = temperatureField.data\n",
    "for index, coord in enumerate(mesh.data):\n",
    "        pertCoeff = (ndp.random_temp*(np.random.rand(1)[0] - 0.5)) #this should create values between [-0.5,0.5] from uniform dist.\n",
    "        ict = tempNump[index]\n",
    "        tempNump[index] = ict + pertCoeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Reset bottom Dirichlet conds.\n",
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TR\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Material Swarm and variables\n",
    "###########\n",
    "\n",
    "gSwarm = uw.swarm.Swarm(mesh=mesh)\n",
    "materialVariable = gSwarm.add_variable( dataType=\"char\", count=1 )\n",
    "rockIntVar = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "airIntVar = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "lithIntVar = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "\n",
    "varlist = [materialVariable, rockIntVar, airIntVar, lithIntVar]\n",
    "varnames = ['materialVariable', 'rockIntVar', 'airIntVar', 'lithIntVar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialise swarm variables\n",
    "\n",
    "mantleIndex = 0\n",
    "lithosphereIndex = 1\n",
    "crustIndex = 2\n",
    "airIndex = 3\n",
    "\n",
    "\n",
    "layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=25)\n",
    "# Now use it to populate.\n",
    "gSwarm.populate_using_layout( layout=layout )\n",
    "\n",
    "materialVariable.data[:] = mantleIndex\n",
    "#Set initial air and crust materials (allow the graph to take care of lithsophere)\n",
    "#########\n",
    "for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "    if (1. - gSwarm.particleCoordinates.data[particleID][1]) < 0:\n",
    "             materialVariable.data[particleID] = airIndex\n",
    "    elif (1. - gSwarm.particleCoordinates.data[particleID][1]) < MANTLETOCRUST:\n",
    "             materialVariable.data[particleID] = crustIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Material Graphs\n",
    "Materials are stored in a directed Graph, this doesn't really add any efficiency, but provided a consistent data structure to query and modify."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All depth conditions are given as (km/D) where D is the length scale,\n",
    "#note that 'model depths' are used, e.g. 1-z, where z is the vertical Underworld coordinate\n",
    "#All temp conditions are in dimensionless temp. [0. - 1.]\n",
    "\n",
    "#Important: All processors need to know about all material types\n",
    "material_list = [0,1,2,3]\n",
    "\n",
    "#######Graph object\n",
    "DG = nx.DiGraph(field=\"Depth\")\n",
    "\n",
    "#######Nodes\n",
    "#Note that the order of materials, deepest to shallowest is important\n",
    "DG.add_node(0, mat='mantle')\n",
    "DG.add_node(1, mat='lithosphere')\n",
    "DG.add_node(2, mat='crust')\n",
    "DG.add_node(3, mat='air')\n",
    "\n",
    "labels=dict((n,d['mat']) for n,d in DG.nodes(data=True))\n",
    "pos=nx.spring_layout(DG)\n",
    "\n",
    "#######Edges\n",
    "#anything to air\n",
    "DG.add_edges_from([(0,3),(1,3), (2,3)])\n",
    "DG[0][3]['depthcondition'] = -1*TOPOHEIGHT\n",
    "DG[1][3]['depthcondition'] = -1*TOPOHEIGHT\n",
    "DG[2][3]['depthcondition'] = -1*TOPOHEIGHT\n",
    "\n",
    "\n",
    "#Anything to mantle\n",
    "DG.add_edges_from([(2,0), (1,0)])\n",
    "DG[2][0]['depthcondition'] = CRUSTTOMANTLE\n",
    "DG[1][0]['depthcondition'] = LITHTOMANTLE #This means we're going to kill lithosphere at the 660.\n",
    "\n",
    "\n",
    "#Anything to lithsphere\n",
    "DG.add_edges_from([(0,1),(3,1)])\n",
    "DG[0][1]['depthcondition'] = MANTLETOLITH\n",
    "DG[0][1]['avgtempcondition'] = 0.75*AVGTEMP #definition of thermal lithosphere\n",
    "\n",
    "\n",
    "#Anything to crust\n",
    "DG.add_edges_from([(0,2), (1,2), (3,2)])\n",
    "DG[0][2]['depthcondition'] = MANTLETOCRUST\n",
    "DG[1][2]['depthcondition'] = MANTLETOCRUST\n",
    "DG[3][2]['depthcondition'] = TOPOHEIGHT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_nodes = []\n",
    "for node in DG.nodes():\n",
    "    if not node in material_list:\n",
    "        remove_nodes.append(node)\n",
    "        \n",
    "for rmnode in remove_nodes:\n",
    "    DG.remove_node(rmnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A Dictionary to map strings in the graph (e.g. 'depthcondition') to particle data arrays\n",
    "\n",
    "particledepths = 1. - gSwarm.particleCoordinates.data[:,1]\n",
    "particletemps = temperatureField.evaluate(gSwarm)[:,0]\n",
    "\n",
    "conditionmap = {}\n",
    "\n",
    "conditionmap['depthcondition'] = {}\n",
    "conditionmap['depthcondition']['data'] = particledepths\n",
    "conditionmap['avgtempcondition'] = {}\n",
    "conditionmap['avgtempcondition']['data'] = particletemps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_swarm(graph, particleIndex):\n",
    "    \"\"\"\n",
    "    This function takes the materials graph (networkx.DiGraph), and a particle index,\n",
    "    then determines if a material update is required \n",
    "    and if so, returns the new materialindex\n",
    "    Args:\n",
    "        graph (networkx.DiGraph): Directed multigraph representing the transformation of material types\n",
    "        particleIndex (int): the particle index as corressponding to the index in the swarm data arrays\n",
    "    Returns:\n",
    "        if update is required the function returns the the new material variable (int) \n",
    "        else returns None\n",
    "    Raises:\n",
    "        TypeError: not implemented\n",
    "        ValueError: not implemented\n",
    "    \"\"\"\n",
    "    ##Egde gives links to other materials, we then query the conditions to see if we should change materials\n",
    "    matId = materialVariable.data[particleIndex][0]\n",
    "    innerchange = False\n",
    "    outerchange = False\n",
    "    for edge in graph[matId]:\n",
    "        if outerchange:\n",
    "            break\n",
    "        for cond in graph[matId][edge].keys():\n",
    "            outerchange = False\n",
    "            if innerchange: #found a complete transition, break inner loop\n",
    "                break\n",
    "            currentparticlevalue = conditionmap[cond]['data'][particleIndex]\n",
    "            crossover = graph[matId][edge][cond]\n",
    "            if ((matId > edge) and (currentparticlevalue > crossover)):\n",
    "                innerchange = False # continue on, \n",
    "                if graph[matId][edge].keys()[-1] == cond:\n",
    "                    outerchange = True\n",
    "                    innerchange = edge\n",
    "                    break\n",
    "            elif ((matId < edge) and (currentparticlevalue < crossover)):\n",
    "                innerchange = False\n",
    "                if graph[matId][edge].keys()[-1] == cond:\n",
    "                    outerchange = True\n",
    "                    innerchange = edge\n",
    "                    break\n",
    "            else:\n",
    "                #condition not met, break outer loop, go to next edge, outerchange should still be False\n",
    "                break\n",
    "    if type(innerchange) == int:\n",
    "        return innerchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fn.branching.conditional?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleanse the swarm of its sins\n",
    "#For some Material Graphs, the graph may have to be treaversed more than once\n",
    "\n",
    "check = -1\n",
    "number_updated = 1\n",
    "\n",
    "while number_updated != 0:\n",
    "    number_updated = 0\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "                check = update_swarm(DG, particleID)\n",
    "                if check > -1:\n",
    "                    number_updated += 1\n",
    "                    materialVariable.data[particleID] = check"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the values for the masking swarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup up a masking Swarm variable for the integrations.\n",
    "#These should be rebuilt at same frequency as the metric calcualtions\n",
    "\n",
    "rockIntVar.data[:] = 0.\n",
    "notair = np.where(materialVariable.data != airIndex)\n",
    "rockIntVar.data[notair] = 1.\n",
    "\n",
    "airIntVar.data[:] = 0.\n",
    "notrock = np.where(materialVariable.data == airIndex)\n",
    "airIntVar.data[notrock] = 1.\n",
    "\n",
    "lithIntVar.data[:] = 0.\n",
    "islith = np.where((materialVariable.data == lithosphereIndex) | (materialVariable.data == crustIndex))\n",
    "lithIntVar.data[islith] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Material properties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, Crameri and Tackley give the dimensionless cohesion as well as the dimensionless yield stress gradient. But the latter is given as a function of dimensionless (lithostatic) pressure, whereas it is easier to use dimensionless depth. Easy, multiply the dimensionless depth by $\\rho g D$, divide by the stress scale, $\\frac{\\eta \\kappa}{D^2}$ then use the same dimensionless yeild stress gradient ($\\mu$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The yeilding of the upper slab is dependent on the strain rate.\n",
    "strainRate_2ndInvariant = fn.tensor.second_invariant( \n",
    "                            fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient ))\n",
    "\n",
    "\n",
    "coordinate = fn.input()\n",
    "depth = 1. - coordinate[1]\n",
    "\n",
    "#Determine yield criterion for depth (rather than pressure as given in Crameri)\n",
    "#Scaling is same as van Heck and Tackley, EPSL, 2011\n",
    "lithopressuregrad = dp.rho*dp.g*(dp.LS)**3/(dp.eta0*dp.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11.55, 3.0, 0.12, 1.0, 0.64, 1577.0)\n"
     ]
    }
   ],
   "source": [
    "#Check important paramters\n",
    "print(ndp.E, ndp.V,ndp.TS,ndp.RD, ndp.TR, ndp.cohesion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ndp.up_visc/ndp.low_visc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Mantle\n",
    "############\n",
    "\n",
    "#Linear viscosity\n",
    "arhennius = fn.misc.min(ndp.up_visc,fn.math.exp(((ndp.E + ndp.V*(1.-coordinate[1]))/\n",
    "                                         (temperatureField + ndp.TS)) - ((ndp.E + ndp.V*(1.- ndp.RD))/(ndp.TR + ndp.TS))))\n",
    "\n",
    "#Plastic viscosity \n",
    "ys =  ndp.cohesion + (depth*ndp.fc*lithopressuregrad)\n",
    "#ys =  ndp.fc*lithopressuregrad*(30e3/dp.LS) # this is the byerlee strength at 30 km\n",
    "yss = fn.misc.max(ndp.cohesion, ys)\n",
    "plasticvisc = yss*(math.sqrt(2))/(strainRate_2ndInvariant*2.)\n",
    "plastic = fn.misc.max(ndp.low_visc,plasticvisc)\n",
    "#combine these\n",
    "mantleviscosityFn = fn.exception.SafeMaths(fn.misc.min(arhennius, plastic))\n",
    "\n",
    "############\n",
    "#crust\n",
    "############\n",
    "ysc = (ndp.cohesion/ndp.cohesion_reduce) + (depth*(ndp.fc/100.)*lithopressuregrad)\n",
    "#ysc = ys/100.\n",
    "ycs = fn.misc.max((ndp.cohesion/ndp.cohesion_reduce), ysc)\n",
    "crustplasticvisc = ycs*(math.sqrt(2))/(strainRate_2ndInvariant*2.)\n",
    "crustplastic = fn.misc.max(ndp.low_visc,crustplasticvisc) \n",
    "#crustviscosityFn = fn.exception.SafeMaths(fn.misc.min(arhennius, crustplastic))\n",
    "crustviscosityFn = fn.exception.SafeMaths(fn.misc.min(1., crustplastic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up material properties\n",
    "====\n",
    "\n",
    "Here the functions for density, viscosity etc. are set. These functions and/or values are preserved for the entire simulation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we set a viscosity value of '1.' for both materials\n",
    "viscosityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:ndp.StAeta0, \n",
    "                                    lithosphereIndex:mantleviscosityFn, \n",
    "                                    crustIndex:crustviscosityFn,\n",
    "                                    mantleIndex:mantleviscosityFn} )\n",
    "\n",
    "densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:ndp.StA, \n",
    "                                    lithosphereIndex:ndp.RA*temperatureField, \n",
    "                                    crustIndex:ndp.RA*temperatureField, \n",
    "                                    mantleIndex:ndp.RA*temperatureField} )\n",
    "\n",
    "# Define our gravity using a python tuple (this will be automatically converted to a function)\n",
    "gravity = ( 0.0, 1.0 )\n",
    "\n",
    "buoyancyFn = gravity*densityMapFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Stokes system, solvers, advection-diffusion\n",
    "------\n",
    "\n",
    "Setup linear Stokes system to get the initial velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stokesPIC = uw.systems.Stokes( velocityField = velocityField, \n",
    "                               pressureField = pressureField,\n",
    "                               #swarm         = gSwarm, \n",
    "                               conditions    = [freeslipBC,],\n",
    "                               fn_viscosity   = arhennius, \n",
    "                               fn_bodyforce   = buoyancyFn,\n",
    "                               swarm=gSwarm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We do one solve with linear viscosity to get the initial strain rate invariant. \n",
    "#This solve step also calculates a 'guess' of the the velocity field based on the linear system, \n",
    "#which is used later in the non-linear solver.\n",
    "\n",
    "solver = uw.systems.Solver(stokesPIC)\n",
    "# If not doing a restart, do a solve on the non-plastic system\n",
    "if not checkpointLoad:\n",
    "    solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<underworld.systems._bsscr.OptionsGroup at 0x1115276d0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "solver.options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "#Add the non-linear viscosity to the Stokes system\n",
    "stokesPIC.fn_viscosity = viscosityMapFn\n",
    "###################\n",
    "\n",
    "#Set more advanced solver option\n",
    "#solver.options.main.Q22_pc_type='gkgdiag'\n",
    "#solver.options.A11.ksp_rtol=1e-2\n",
    "#solver.options.scr.ksp_rtol=1e-3\n",
    "#solver.options.A11.ksp_type=\"cg\"\n",
    "solver.options.scr.use_previous_guess = True\n",
    "#solver.options.scr.ksp_set_min_it_converge = 1\n",
    "#solver.options.main.penalty=10.0\n",
    "\n",
    "solver.options.mg.levels = 3\n",
    "#solver.options.main.remove_constant_pressure_null_space=True\n",
    "#solver.options.main.penalty = 1e2\n",
    "\n",
    "#solver.options.A11.ksp_rtol=1e-4\n",
    "#solver.options.scr.ksp_rtol=1e-4\n",
    "\n",
    "solver.options.A11.ksp_monitor=''\n",
    "solver.options.A11.ksp_converged_reason=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solve non-linear using point iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.solve(nonLinearIterate=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create an advective-diffusive system\n",
    "\n",
    "Setup the system in underworld by flagging the temperature and velocity field variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create advdiff system\n",
    "\n",
    "advDiff = uw.systems.AdvectionDiffusion( phiField       = temperatureField, \n",
    "                                         phiDotField    = temperatureDotField, \n",
    "                                         velocityField  = velocityField,\n",
    "                                         fn_sourceTerm    = 20.0,\n",
    "                                         fn_diffusivity = 1.0, \n",
    "                                         conditions     = [neumannTempBC, dirichTempBC] )\n",
    "\n",
    "\n",
    "\n",
    "advector = uw.systems.SwarmAdvector( swarm         = gSwarm, \n",
    "                                     velocityField = velocityField, \n",
    "                                     order         = 1)\n",
    "\n",
    "#Switch particle escape on, this will also trigger the inflow population control \n",
    "gSwarm.particleEscape = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Pack some stuff into a database as well\n",
    "figDb = glucifer.Figure()\n",
    "figDb.append( glucifer.objects.Points(gSwarm,viscVariable, logScale=True, colours='brown white blue'))\n",
    "figDb.append( glucifer.objects.Points(gSwarm,materialVariable, colours='brown white blue red'))\n",
    "figDb.append( glucifer.objects.Mesh(mesh))\n",
    "figDb.append( glucifer.objects.VectorArrows(mesh,velocityField, arrowHead=0.2, scaling=0.002))\n",
    "figDb.append( glucifer.objects.Surface(mesh, strainRate_2ndInvariant, logScale=True, colours='brown white blue'))\n",
    "figDb.append( glucifer.objects.Surface(mesh, temperatureField))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main simulation loop\n",
    "=======\n",
    "\n",
    "The main time stepping loop begins here. Before this the time and timestep are initialised to zero and the output statistics arrays are set up. Also the frequency of outputting basic statistics to the screen is set in steps_output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pics = uw.swarm.PICIntegrationSwarm(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "start = time.clock()\n",
    "# setup summary output file (name above)\n",
    "if checkpointLoad:\n",
    "    if uw.rank() == 0:\n",
    "        shutil.copyfile(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    comm.Barrier()\n",
    "    f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "    prevdata = np.genfromtxt(os.path.join(outputPath, outputFile), skip_header=0, skip_footer=0)\n",
    "    if len(prevdata.shape) == 1: #this is in case there is only one line in previous file\n",
    "        realtime = prevdata[0]\n",
    "    else:\n",
    "        realtime = prevdata[prevdata.shape[0]-1, 0]\n",
    "    step = int(checkpointLoadDir.split('/')[-1])\n",
    "    timevals = [0.]\n",
    "else:\n",
    "    f_o = open(outputPath+outputFile, 'w')\n",
    "    realtime = 0.\n",
    "    step = 0\n",
    "    timevals = [0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "step = 5\n"
     ]
    }
   ],
   "source": [
    "# initialise timer for computation\n",
    "startMain = time.clock()\n",
    "# Perform steps\n",
    "while realtime < 0.05:\n",
    "#while step < 5:\n",
    "    #Enter non-linear loop\n",
    "    print step\n",
    "    solver.solve(nonLinearIterate=True)\n",
    "    dt = advDiff.get_max_dt()\n",
    "    if step == 0:\n",
    "        dt = 0.\n",
    "    advDiff.integrate(dt)\n",
    "    advector.integrate(dt)\n",
    "    realtime += dt\n",
    "    step += 1\n",
    "    timevals.append(realtime)\n",
    "    \n",
    "    ################\n",
    "    #Update temperature field in the air region\n",
    "    ################\n",
    "    if (step % sticky_air_temp == 0):\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= 1.:\n",
    "                temperatureField.data[index] = dp.TS/dp.deltaT\n",
    " \n",
    "    ################\n",
    "    #Particle update\n",
    "    ###############\n",
    "    if (step % swarm_update == 0) or (step % metric_output == 0): #These updates should be done before any metric output\n",
    "        #These swarm variables get updated first, as they are used to determine material changes\n",
    "        particledepths = 1. - gSwarm.particleCoordinates.data[:,1]\n",
    "        particletemps = temperatureField.evaluate(gSwarm)[:,0]\n",
    "        conditionmap['depthcondition']['data'] = particledepths\n",
    "        conditionmap['avgtempcondition']['data'] = particletemps\n",
    "        ################\n",
    "        number_updated = 0\n",
    "        for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "            check = update_swarm(DG, particleID)\n",
    "            if check > -1:\n",
    "                number_updated += 1\n",
    "                #if check == 0:\n",
    "                #    print \"from \" + str(materialVariable.data[particleID]) + \" to \" + str(check)\n",
    "                materialVariable.data[particleID] = check\n",
    "            else:\n",
    "                pass\n",
    "        #Also update those integration swarms\n",
    "        rockIntVar.data[:] = 0.\n",
    "        notair = np.where(materialVariable.data != airIndex)\n",
    "        rockIntVar.data[notair] = 1.\n",
    "        airIntVar.data[:] = 0.\n",
    "        notrock = np.where(materialVariable.data == airIndex)\n",
    "        airIntVar.data[notrock] = 1.\n",
    "        lithIntVar.data[:] = 0.\n",
    "        islith = np.where((materialVariable.data == lithosphereIndex) | (materialVariable.data == crustIndex))\n",
    "        lithIntVar.data[islith] = 1.\n",
    "    ################\n",
    "    #Gldb output\n",
    "    ################ \n",
    "    if (step % gldbs_output == 0) & (writeFiles == True):\n",
    "        #Rebuild any necessary swarm variables\n",
    "        viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)\n",
    "        #Write gldbs\n",
    "        fnamedb = \"dbFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".gldb\"\n",
    "        fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "        figDb.show()\n",
    "        figDb.save_database(fullpath)\n",
    "    ################\n",
    "    #Also repopulate entire swarm periodically\n",
    "    ################\n",
    "    if step % swarm_repop == 0:\n",
    "        pics.repopulate()\n",
    "        \n",
    "f_o.close()\n",
    "print 'step =',step"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
