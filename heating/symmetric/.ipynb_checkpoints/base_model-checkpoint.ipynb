{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "Crameri-Tackley model\n",
    "=======\n",
    "\n",
    "From Cramer and Tackley 2015\n",
    "--------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "\n",
    "\n",
    "\n",
    "References\n",
    "====\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load python functions needed for underworld. Some additional python functions from os, math and numpy used later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import networkx as nx\n",
    "import underworld as uw\n",
    "import math\n",
    "from underworld import function as fn\n",
    "import glucifer\n",
    "#import matplotlib.pyplot as pyplot\n",
    "import time\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import natsort\n",
    "import shutil\n",
    "from easydict import EasyDict as edict\n",
    "import collections\n",
    "import slippy2 as sp\n",
    "\n",
    "from mpi4py import MPI\n",
    "comm = MPI.COMM_WORLD\n",
    "rank = comm.Get_rank()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Display working directory info if in nb mode\n",
    "if (len(sys.argv) > 1):\n",
    "    if (sys.argv[1] == '-f'):\n",
    "        !pwd && ls\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Model name.  \n",
    "############\n",
    "Model = \"T\"\n",
    "ModNum = 0\n",
    "\n",
    "if len(sys.argv) == 1:\n",
    "    ModIt = \"Base\"\n",
    "elif sys.argv[1] == '-f':\n",
    "    ModIt = \"Base\"\n",
    "else:\n",
    "    ModIt = str(sys.argv[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set physical constants and parameters, including the Rayleigh number (*RA*). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Standard output directory setup\n",
    "###########\n",
    "\n",
    "\n",
    "outputPath = \"results\" + \"/\" +  str(Model) + \"/\" + str(ModNum) + \"/\" + str(ModIt) + \"/\"\n",
    "imagePath = outputPath + 'images/'\n",
    "filePath = outputPath + 'files/'\n",
    "checkpointPath = outputPath + 'checkpoint/'\n",
    "dbPath = outputPath + 'gldbs/'\n",
    "outputFile = 'results_model' + Model + '_' + str(ModNum) + '_' + str(ModIt) + '.dat'\n",
    "\n",
    "if uw.rank()==0:\n",
    "    # make directories if they don't exist\n",
    "    if not os.path.isdir(outputPath):\n",
    "        os.makedirs(outputPath)\n",
    "    if not os.path.isdir(checkpointPath):\n",
    "        os.makedirs(checkpointPath)\n",
    "    if not os.path.isdir(imagePath):\n",
    "        os.makedirs(imagePath)\n",
    "    if not os.path.isdir(dbPath):\n",
    "        os.makedirs(dbPath)\n",
    "    if not os.path.isdir(filePath):\n",
    "        os.makedirs(filePath)\n",
    "        \n",
    "comm.Barrier() #Barrier here so not procs run the check in the next cell too early "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Check if starting from checkpoint\n",
    "###########\n",
    "\n",
    "checkdirs = []\n",
    "for dirpath, dirnames, files in os.walk(checkpointPath):\n",
    "    if files:\n",
    "        print dirpath, 'has files'\n",
    "        checkpointLoad = True\n",
    "        checkdirs.append(dirpath)\n",
    "    if not files:\n",
    "        print dirpath, 'is empty'\n",
    "        checkpointLoad = False\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Physical parameters\n",
    "###########\n",
    "\n",
    "#The Slippy rheology class will contain dimensional and nondimensional values, linked in a self-consistent way by scaling paramters\n",
    "#lowermantle.nondimensional['cohesion']\n",
    "#Where lowermantle is a material class (generated within a rheology class); and non dimensional is a dictionary\n",
    "\n",
    "#UW naming conventions: \n",
    "#module_name, package_name, ClassName, function_name, method_name, \n",
    "#ExceptionName, propertyName GLOBAL_CONSTANT_NAME, globalVarName, instanceVarName, functionParameterName, localVarName\n",
    "###########\n",
    "\n",
    "\n",
    "#dimensional parameter dictionary\n",
    "dp = edict({'LS':2890.*1e3,\n",
    "           'rho':3300,\n",
    "           'g':9.81, \n",
    "           'eta0':1e23,\n",
    "           'k':10**-6,\n",
    "           'a':1.25*10**-5, \n",
    "           'TS':300.,\n",
    "           'TB':2800.,\n",
    "           'deltaT':2500., \n",
    "           'cohesion':1e7, \n",
    "           'E':240000., \n",
    "           'R':8.314,\n",
    "           'V':6.34*(10**-7),\n",
    "           'StALS': 150e3})\n",
    "\n",
    "#non-dimensional parameter dictionary\n",
    "#One draw back of a dictionary structure, is that variables cannot link to other variables\n",
    "RAfac = 1.\n",
    "ndp = edict({'RA':1e6*RAfac,      \n",
    "              'LS':1.,\n",
    "              'eta0':1.,\n",
    "              'StAeta0':0.01,\n",
    "              'k':1.,\n",
    "              'E':11.55,\n",
    "              'V':3.0,\n",
    "              'H':20.,\n",
    "              'TR':(1600./2500.),\n",
    "              'TS':(dp.TS/2500.),\n",
    "              'RD':1.,\n",
    "              'cohesion':1577.*RAfac,\n",
    "              'cohesion_reduce':10.,\n",
    "              'fc':0.1, \n",
    "              'low_visc':RAfac*5e-4,\n",
    "              'up_visc':5e4,\n",
    "              'random_temp': 0.05})\n",
    "\n",
    "\n",
    "#A few parameters defining lengths scales, affects materal transistions etc.\n",
    "#MANTLETOCRUST = (18.*1e3)/dp.LS #Crust depth\n",
    "MANTLETOCRUST = (24.*1e3)/dp.LS #Crust depth\n",
    "\n",
    "CRUSTTOMANTLE = (900.*1e3)/dp.LS \n",
    "LITHTOMANTLE = (900.*1e3)/dp.LS \n",
    "MANTLETOLITH = (200.*1e3)/dp.LS \n",
    "TOPOHEIGHT = (20.*1e3)/dp.LS  #rock-air topography limits\n",
    "AVGTEMP = 0.53 #Used to define lithosphere\n",
    "\n",
    "\n",
    "#Compositional Rayliegh number of rock-air\n",
    "ETAREF = dp.rho*dp.g*dp.a*dp.deltaT*((dp.LS)**3)/(ndp.RA*dp.k) #equivalent dimensional reference viscosity\n",
    "RC = (3300.*dp.g*(dp.LS)**3)/(ETAREF *dp.k) #Composisitional Rayleigh number for rock-air buoyancy force\n",
    "#RC = (1650.*dp.g*(dp.LS)**3)/(ETAREF *dp.k) #Composisitional Rayleigh number for rock-air buoyancy force\n",
    "\n",
    "COMP_RA_FACT = RC/ndp.RA\n",
    "\n",
    "\n",
    "#Additional dimensionless paramters\n",
    "\n",
    "ndp[\"StA\"] = ndp.RA*COMP_RA_FACT\n",
    "\n",
    "\n",
    "#######################To be replaced soon\n",
    "#Physical parameters that can be defined with STDIN,\n",
    "#The == '-f': check is a a hack check to see cover the notebook case\n",
    "if len(sys.argv) == 1:\n",
    "    ndp.cohesion = ndp.cohesion\n",
    "elif sys.argv[1] == '-f':\n",
    "    ndp.cohesion = ndp.cohesion\n",
    "else:\n",
    "    ndp.cohesion = float(sys.argv[1])*newvisc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model setup parameters\n",
    "###########\n",
    "\n",
    "stickyAir = True\n",
    "\n",
    "MINX = -1.\n",
    "MINY = 0.\n",
    "MAXX = 1.0\n",
    "\n",
    "#MAXY = 1.035\n",
    "MAXY = 1.\n",
    "\n",
    "if MINX == 0.:\n",
    "    squareModel = True\n",
    "else: \n",
    "    squareModel = False\n",
    "    \n",
    "    \n",
    "dim = 2          # number of spatial dimensions\n",
    "\n",
    "\n",
    "#MESH STUFF\n",
    "\n",
    "RES = 192\n",
    "\n",
    "if MINX == 0.:\n",
    "    Xres = RES\n",
    "else:\n",
    "    Xres = 2*RES\n",
    "\n",
    "if stickyAir:\n",
    "    Yres = RES\n",
    "    MAXY = 1. + dp.StALS/dp.LS #150km\n",
    "    \n",
    "else:\n",
    "    Yres = RES\n",
    "    MAXY = 1.\n",
    "\n",
    "\n",
    "periodic = [True, False]\n",
    "elementType = \"Q1/dQ0\"\n",
    "#elementType =\"Q2/DPC1\"\n",
    "\n",
    "refineMesh = False\n",
    "\n",
    "#System/Solver stuff\n",
    "\n",
    "PIC_integration=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model Runtime parameters\n",
    "###########\n",
    "\n",
    "swarm_update = 25\n",
    "swarm_repop = 25\n",
    "files_output = 1e6\n",
    "gldbs_output = 25\n",
    "images_output = 1e6\n",
    "checkpoint_every = 25\n",
    "metric_output = 25\n",
    "sticky_air_temp = 5\n",
    "\n",
    "comm.Barrier() #Barrier here so not procs run the check in the next cell too early \n",
    "\n",
    "assert metric_output <= checkpoint_every, 'Checkpointing should run less or as ofen as metric output'\n",
    "assert (metric_output >= swarm_update), 'Swarm update is needed before checkpointing'\n",
    "assert metric_output >= sticky_air_temp, 'Sticky air temp should be updated more frequently that metrics'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Model output parameters\n",
    "###########\n",
    "\n",
    "#Do you want to write hdf5 files - Temp, RMS, viscosity, stress?\n",
    "writeFiles = True\n",
    "loadTemp = True\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mesh = uw.mesh.FeMesh_Cartesian( elementType = (\"Q1/dQ0\"),\n",
    "                                 elementRes  = (Xres, Yres), \n",
    "                                 minCoord    = (MINX,MINY), \n",
    "                                 maxCoord=(MAXX,MAXY), periodic=periodic)\n",
    "\n",
    "\n",
    "\n",
    "velocityField       = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=dim )\n",
    "pressureField       = uw.mesh.MeshVariable( mesh=mesh.subMesh, nodeDofCount=1 )\n",
    "temperatureField    = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )\n",
    "temperatureDotField = uw.mesh.MeshVariable( mesh=mesh,         nodeDofCount=1 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(\"mesh size\", mesh.data.shape, mesh.elementRes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Xres, Yres, MINX,MAXX,MINY,MAXY, periodic, elementType, dim "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Refine mesh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#X-Axis\n",
    "\n",
    "if refineMesh:\n",
    "    mesh.reset()\n",
    "    axis = 0\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (abs(mesh.maxCoord[axis]) - abs(mesh.minCoord[axis]))/2.\n",
    "    el_reduction = 0.6\n",
    "    dx = mesh.maxCoord[axis] - min_point\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction) *deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    sp.deform_1d(deform_lengths, mesh,axis = 'x',norm = 'Min', constraints = [])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "axis = 1\n",
    "orgs = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "\n",
    "value_to_constrain = 1.\n",
    "\n",
    "\n",
    "yconst = [(sp.find_closest(orgs, value_to_constrain), np.array([value_to_constrain,0]))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Y-Axis\n",
    "if refineMesh:\n",
    "    #Y-Axis\n",
    "    axis = 1\n",
    "    origcoords = np.linspace(mesh.minCoord[axis], mesh.maxCoord[axis], mesh.elementRes[axis] + 1)\n",
    "    edge_rest_lengths = np.diff(origcoords)\n",
    "\n",
    "    deform_lengths = edge_rest_lengths.copy()\n",
    "    min_point =  (mesh.maxCoord[axis])\n",
    "    el_reduction = 0.6\n",
    "    dx = mesh.maxCoord[axis]\n",
    "\n",
    "    deform_lengths = deform_lengths - \\\n",
    "                                    ((1.-el_reduction)*deform_lengths[0]) + \\\n",
    "                                    abs((origcoords[1:] - min_point))*((0.5*deform_lengths[0])/dx)\n",
    "\n",
    "    #print(edge_rest_lengths.shape, deform_lengths.shape)\n",
    "\n",
    "    sp.deform_1d(deform_lengths, mesh,axis = 'y',norm = 'Min', constraints = yconst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figMesh = glucifer.Figure(figsize=(1200,600),antialias=1)\n",
    "#figMesh.append( glucifer.objects.Mesh(mesh.subMesh, nodeNumbers=True) )\n",
    "figMesh.append( glucifer.objects.Mesh(mesh) )\n",
    "figMesh.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ICs and BCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Get the actual sets \n",
    "#\n",
    "#  HJJJJJJH\n",
    "#  I      I\n",
    "#  I      I\n",
    "#  I      I\n",
    "#  HJJJJJJH\n",
    "#  \n",
    "#  Note that H = I & J \n",
    "\n",
    "# Note that we use operator overloading to combine sets\n",
    "# send boundary condition information to underworld\n",
    "IWalls = mesh.specialSets[\"MinI_VertexSet\"] + mesh.specialSets[\"MaxI_VertexSet\"]\n",
    "JWalls = mesh.specialSets[\"MinJ_VertexSet\"] + mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "TWalls = mesh.specialSets[\"MaxJ_VertexSet\"]\n",
    "BWalls = mesh.specialSets[\"MinJ_VertexSet\"]\n",
    "AWalls = IWalls + JWalls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialise data.. Note that we are also setting boundary conditions here\n",
    "velocityField.data[:] = [0.,0.]\n",
    "pressureField.data[:] = 0.\n",
    "temperatureField.data[:] = 0.\n",
    "temperatureDotField.data[:] = 0.\n",
    "\n",
    "def wbl(x, w0 = 0.06):\n",
    "    delx = 1- abs(x)\n",
    "    Wbl = w0*math.sqrt(delx)\n",
    "    if Wbl== 0.: #to avoid division by zero\n",
    "        Wbl = 1e-8\n",
    "    return Wbl\n",
    "\n",
    "\n",
    "def tempf(z,w,tm=0.64, ts = 0.12):\n",
    "    temp = (tm - ts) *math.erf((1-z)/w) + ts\n",
    "    return temp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tempf(0.5, 0.095)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "age_asymmetry = 1.\n",
    "\n",
    "for index, coord in enumerate(mesh.data):\n",
    "    if coord[0] > 0.:\n",
    "        w = wbl(coord[0])\n",
    "        t = tempf(coord[1], w)\n",
    "        temperatureField.data[index] = t\n",
    "    else:\n",
    "        w = wbl(coord[0])/age_asymmetry\n",
    "        t = tempf(coord[1], w)\n",
    "        temperatureField.data[index] = t\n",
    "        \n",
    "\n",
    "\n",
    "#for index, coord in enumerate(mesh.data):\n",
    "#    if abs(coord[0]) < wbl(0)/2. and coord[1] > 0.5:\n",
    "#        w = wbl(0)/2.\n",
    "#        d = w - abs(coord[0])\n",
    "#        t = tempf(d, coord[1], w)\n",
    "#        temperatureField.data[index] = t\n",
    "        \n",
    "for index, coord in enumerate(mesh.data):\n",
    "    if abs(coord[0]) < wbl(0)/2. and coord[1] > 0.5 and coord[1] < 0.99:\n",
    "        w = wbl(0)\n",
    "        d = 1. - abs(coord[0])\n",
    "        t = tempf(d, w)\n",
    "        temperatureField.data[index] = t\n",
    "        \n",
    "        \n",
    "\n",
    "#Set sticky air Temp to zero\n",
    "for index, coord in enumerate(mesh.data):\n",
    "    if coord[1] > 1.:\n",
    "        temperatureField.data[index] = dp.TS/dp.deltaT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#figTemp = glucifer.Figure()\n",
    "#figTemp.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "#figTemp.append( glucifer.objects.Mesh(mesh))\n",
    "\n",
    "#figTemp.append( glucifer.objects.VectorArrows(mesh,velocityField, arrowHead=0.2, scaling=0.01))\n",
    "#figTemp.save_database('test.gldb')\n",
    "#figTemp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#For notebook runs\n",
    "#ModIt = \"96\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Now setup the dirichlet boundary condition\n",
    "# Note that through this object, we are flagging to the system \n",
    "# that these nodes are to be considered as boundary conditions. \n",
    "# Also note that we provide a tuple of sets.. One for the Vx, one for Vy.\n",
    "freeslipBC = uw.conditions.DirichletCondition( variable      = velocityField, \n",
    "                                               indexSetsPerDof = (None, JWalls) )\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "dirichTempBC = uw.conditions.DirichletCondition(     variable=temperatureField, \n",
    "                                              indexSetsPerDof=(TWalls,) )\n",
    "dT_dy = [0.,0.]\n",
    "\n",
    "# also set dirichlet for temp field\n",
    "neumannTempBC = uw.conditions.NeumannCondition( dT_dy, variable=temperatureField, \n",
    "                                         indexSetsPerDof=BWalls)\n",
    "\n",
    "\n",
    "# set initial conditions (and boundary values)\n",
    "velocityField.data[:] = [0.,0.]\n",
    "pressureField.data[:] = 0.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "##Add Random 125 K temp perturbation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tempNump = temperatureField.data\n",
    "\n",
    "#In gerneral we only want to do this on the initial setup, not restarts\n",
    "#Takes an input from the ndp dictionary: ndp.random_temp\n",
    "\n",
    "\n",
    "\n",
    "if not checkpointLoad:\n",
    "    for index, coord in enumerate(mesh.data):\n",
    "        pertCoeff = (ndp.random_temp*(np.random.rand(1)[0] - 0.5)) #this should create values between [-0.5,0.5] from uniform dist.\n",
    "        ict = tempNump[index]\n",
    "        tempNump[index] = ict + pertCoeff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##Reset bottom Dirichlet conds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Set temp boundaries \n",
    "# on the boundaries\n",
    "for index in mesh.specialSets[\"MinJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TR\n",
    "for index in mesh.specialSets[\"MaxJ_VertexSet\"]:\n",
    "    temperatureField.data[index] = ndp.TS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#temperatureField.evaluate(IWalls).min()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Particles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Material Swarm and variables\n",
    "###########\n",
    "\n",
    "gSwarm = uw.swarm.Swarm(mesh=mesh)\n",
    "materialVariable = gSwarm.add_variable( dataType=\"char\", count=1 )\n",
    "rockIntVar = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "airIntVar = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "lithIntVar = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "\n",
    "varlist = [materialVariable, rockIntVar, airIntVar, lithIntVar]\n",
    "varnames = ['materialVariable', 'rockIntVar', 'airIntVar', 'lithIntVar']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "###########\n",
    "#Swarms for surface intragrals when using Sticky air\n",
    "###########\n",
    "\n",
    "snum = 1000.\n",
    "dx = (mesh.data[:,0].max()- mesh.data[:,0].min())/snum\n",
    "yp = 0.9947 #1. - yelsize/2. at res = 96\n",
    "\n",
    "mesh.data[:,0].max()\n",
    "xps = np.linspace(mesh.data[:,0].min(),mesh.data[:,0].max(), snum)\n",
    "yps = [yp for i in xps]\n",
    "\n",
    "surfintswarm = uw.swarm.Swarm( mesh=mesh )\n",
    "dumout = surfintswarm.add_particles_with_coordinates(np.array((xps,yps)).T)\n",
    "\n",
    "yps = [ 1.- yp  for i in xps]\n",
    "\n",
    "baseintswarm = uw.swarm.Swarm( mesh=mesh)\n",
    "dumout = baseintswarm.add_particles_with_coordinates(np.array((xps,yps)).T)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Initialise swarm variables, or Swarm checkpoint load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mantleIndex = 0\n",
    "lithosphereIndex = 1\n",
    "crustIndex = 2\n",
    "airIndex = 3\n",
    "\n",
    "\n",
    "if checkpointLoad:\n",
    "    checkpointLoadDir = natsort.natsorted(checkdirs)[-1]\n",
    "    temperatureField.load(os.path.join(checkpointLoadDir, \"temperatureField\" + \".hdf5\"))\n",
    "    pressureField.load(os.path.join(checkpointLoadDir, \"pressureField\" + \".hdf5\"))\n",
    "    velocityField.load(os.path.join(checkpointLoadDir, \"velocityField\" + \".hdf5\"))\n",
    "    gSwarm.load(os.path.join(checkpointLoadDir, \"swarm\" + \".h5\"))\n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.load(os.path.join(checkpointLoadDir,varnames[ix] + \".h5\"))\n",
    "\n",
    "else:\n",
    "\n",
    "    # Layouts are used to populate the swarm across the whole domain\n",
    "    # Create the layout object\n",
    "    #layout = uw.swarm.layouts.GlobalSpaceFillerLayout( swarm=gSwarm, particlesPerCell=20)\n",
    "    #layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=15)\n",
    "    layout = uw.swarm.layouts.PerCellRandomLayout(swarm=gSwarm, particlesPerCell=25)\n",
    "    # Now use it to populate.\n",
    "    gSwarm.populate_using_layout( layout=layout )\n",
    "\n",
    "    # Lets initialise the 'materialVariable' data to represent different materials\n",
    "    # Set the material to heavy everywhere via the numpy array\n",
    "    materialVariable.data[:] = mantleIndex\n",
    "    \n",
    "    \n",
    "    #Set initial air and crust materials (allow the graph to take care of lithsophere)\n",
    "    #########\n",
    "    #This initial material setup will be model dependent\n",
    "    #########\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "        if (1. - gSwarm.particleCoordinates.data[particleID][1]) < 0:\n",
    "                 materialVariable.data[particleID] = airIndex\n",
    "        elif (1. - gSwarm.particleCoordinates.data[particleID][1]) < MANTLETOCRUST:\n",
    "                 materialVariable.data[particleID] = crustIndex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Material Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "##############\n",
    "#Important: This is a quick fix for a bug that arises in parallel runs\n",
    "##############\n",
    "material_list = [0,1,2,3]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print( \"unique values after swarm has loaded:\" + str(np.unique(materialVariable.data[:])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#All depth conditions are given as (km/D) where D is the length scale,\n",
    "#note that 'model depths' are used, e.g. 1-z, where z is the vertical Underworld coordinate\n",
    "#All temp conditions are in dimensionless temp. [0. - 1.]\n",
    "\n",
    "#######Graph object\n",
    "DG = nx.DiGraph(field=\"Depth\")\n",
    "\n",
    "#######Nodes\n",
    "#Note that the order of materials, deepest to shallowest is important\n",
    "DG.add_node(0, mat='mantle')\n",
    "DG.add_node(1, mat='lithosphere')\n",
    "DG.add_node(2, mat='crust')\n",
    "DG.add_node(3, mat='air')\n",
    "\n",
    "\n",
    "labels=dict((n,d['mat']) for n,d in DG.nodes(data=True))\n",
    "pos=nx.spring_layout(DG)\n",
    "\n",
    "\n",
    "#######Edges\n",
    "#anything to air\n",
    "DG.add_edges_from([(0,3),(1,3), (2,3)])\n",
    "DG[0][3]['depthcondition'] = -1*TOPOHEIGHT\n",
    "DG[1][3]['depthcondition'] = -1*TOPOHEIGHT\n",
    "DG[2][3]['depthcondition'] = -1*TOPOHEIGHT\n",
    "\n",
    "\n",
    "#Anything to mantle\n",
    "DG.add_edges_from([(2,0), (1,0)])\n",
    "DG[2][0]['depthcondition'] = CRUSTTOMANTLE\n",
    "DG[1][0]['depthcondition'] = LITHTOMANTLE #This means we're going to kill lithosphere at the 660.\n",
    "\n",
    "\n",
    "#Anything to lithsphere\n",
    "DG.add_edges_from([(0,1),(3,1)])\n",
    "DG[0][1]['depthcondition'] = MANTLETOLITH\n",
    "DG[0][1]['avgtempcondition'] = 0.75*AVGTEMP #definition of thermal lithosphere\n",
    "\n",
    "\n",
    "#Anything to crust\n",
    "DG.add_edges_from([(0,2), (1,2), (3,2)])\n",
    "DG[0][2]['depthcondition'] = MANTLETOCRUST\n",
    "DG[1][2]['depthcondition'] = MANTLETOCRUST\n",
    "DG[3][2]['depthcondition'] = TOPOHEIGHT\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DG.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "remove_nodes = []\n",
    "for node in DG.nodes():\n",
    "    if not node in material_list:\n",
    "        remove_nodes.append(node)\n",
    "        \n",
    "for rmnode in remove_nodes:\n",
    "    DG.remove_node(rmnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "DG.nodes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "#remove_nodes = []\n",
    "#for node in DG.nodes_iter():\n",
    "#    if not node in material_list:\n",
    "#        remove_nodes.append(node)\n",
    "        \n",
    "#for rmnode in remove_nodes:\n",
    "#    DG.remove_node(rmnode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#A Dictionary to map strings in the graph (e.g. 'depthcondition') to particle data arrays\n",
    "\n",
    "particledepths = 1. - gSwarm.particleCoordinates.data[:,1]\n",
    "particletemps = temperatureField.evaluate(gSwarm)[:,0]\n",
    "\n",
    "conditionmap = {}\n",
    "\n",
    "conditionmap['depthcondition'] = {}\n",
    "conditionmap['depthcondition']['data'] = particledepths\n",
    "conditionmap['avgtempcondition'] = {}\n",
    "conditionmap['avgtempcondition']['data'] = particletemps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def update_swarm(graph, particleIndex):\n",
    "    \"\"\"\n",
    "    This function takes the materials graph (networkx.DiGraph), and a particle index,\n",
    "    then determines if a material update is required \n",
    "    and if so, returns the new materialindex\n",
    "    Args:\n",
    "        graph (networkx.DiGraph): Directed multigraph representing the transformation of material types\n",
    "        particleIndex (int): the particle index as corressponding to the index in the swarm data arrays\n",
    "    Returns:\n",
    "        if update is required the function returns the the new material variable (int) \n",
    "        else returns None\n",
    "    Raises:\n",
    "        TypeError: not implemented\n",
    "        ValueError: not implemented\n",
    "    \"\"\"\n",
    "    ##Egde gives links to other materials, we then query the conditions to see if we should change materials\n",
    "    matId = materialVariable.data[particleIndex][0]\n",
    "    innerchange = False\n",
    "    outerchange = False\n",
    "    for edge in graph[matId]:\n",
    "        if outerchange:\n",
    "            break\n",
    "        for cond in graph[matId][edge].keys():\n",
    "            outerchange = False\n",
    "            if innerchange: #found a complete transition, break inner loop\n",
    "                break\n",
    "            currentparticlevalue = conditionmap[cond]['data'][particleIndex]\n",
    "            crossover = graph[matId][edge][cond]\n",
    "            if ((matId > edge) and (currentparticlevalue > crossover)):\n",
    "                innerchange = False # continue on, \n",
    "                if graph[matId][edge].keys()[-1] == cond:\n",
    "                    outerchange = True\n",
    "                    innerchange = edge\n",
    "                    break\n",
    "            elif ((matId < edge) and (currentparticlevalue < crossover)):\n",
    "                innerchange = False\n",
    "                if graph[matId][edge].keys()[-1] == cond:\n",
    "                    outerchange = True\n",
    "                    innerchange = edge\n",
    "                    break\n",
    "            else:\n",
    "                #condition not met, break outer loop, go to next edge, outerchange should still be False\n",
    "                break\n",
    "    if type(innerchange) == int:\n",
    "        return innerchange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#fn.branching.conditional?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Cleanse the swarm of its sins\n",
    "#For some Material Graphs, the graph may have to be treaversed more than once\n",
    "\n",
    "check = -1\n",
    "number_updated = 1\n",
    "\n",
    "while number_updated != 0:\n",
    "    number_updated = 0\n",
    "    for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "                check = update_swarm(DG, particleID)\n",
    "                if check > -1:\n",
    "                    number_updated += 1\n",
    "                    materialVariable.data[particleID] = check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Here we'll play around with some different crust-perturbations\n",
    "##Voul inlude this is the Graph update function, but for now keep it seperate\n",
    "\n",
    "#MANTLETOCRUST\n",
    "centre = 0.0\n",
    "#CRUSTTOMANTLE\n",
    "\n",
    "square_shape = np.array([ (MANTLETOCRUST ,1. ), (-1.*MANTLETOCRUST ,1. ), ((-1.*MANTLETOCRUST) , \n",
    "                       (1.0 - CRUSTTOMANTLE/2.) ), ((MANTLETOCRUST),(1.0 - CRUSTTOMANTLE/2.))])\n",
    "square_shape = fn.shape.Polygon( square_shape)\n",
    "\n",
    "sub_zone1 = np.array([ ((2*MANTLETOCRUST + 0.5*MANTLETOLITH),1. ), ((-2.*MANTLETOCRUST + 0.5*MANTLETOLITH) ,1. ), \n",
    "                     ((-2.*MANTLETOCRUST - 0.5*MANTLETOLITH ) ,(1.0 - CRUSTTOMANTLE/2.) ), ((2*MANTLETOCRUST - 0.5*MANTLETOLITH ),(1.0 - CRUSTTOMANTLE/2. )) ])\n",
    "shape1 = fn.shape.Polygon( sub_zone1)\n",
    "\n",
    "\n",
    "if not checkpointLoad:\n",
    "    for particleID in range( gSwarm.particleCoordinates.data.shape[0] ):\n",
    "        if square_shape.evaluate(tuple(gSwarm.particleCoordinates.data[particleID])):\n",
    "    #        #print \"true\"\n",
    "            materialVariable.data[particleID] = crustIndex\n",
    "        #elif shape2.evaluate(tuple(gSwarm.particleCoordinates.data[particleID])):\n",
    "        #    materialVariable.data[particleID] = crustIndex\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figSwarm = glucifer.Figure(figsize=(1024,384))\n",
    "figSwarm.append( glucifer.objects.Points(gSwarm,materialVariable, colours='brown white blue red'))\n",
    "#figSwarm.append( glucifer.objects.Mesh(mesh))\n",
    "figSwarm.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "figSwarm.save_database('test.gldb')\n",
    "figSwarm.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the values for the masking swarms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup up a masking Swarm variable for the integrations.\n",
    "#These should be rebuilt at same frequency as the metric calcualtions\n",
    "\n",
    "rockIntVar.data[:] = 0.\n",
    "notair = np.where(materialVariable.data != airIndex)\n",
    "rockIntVar.data[notair] = 1.\n",
    "\n",
    "airIntVar.data[:] = 0.\n",
    "notrock = np.where(materialVariable.data == airIndex)\n",
    "airIntVar.data[notrock] = 1.\n",
    "\n",
    "lithIntVar.data[:] = 0.\n",
    "islith = np.where((materialVariable.data == lithosphereIndex) | (materialVariable.data == crustIndex))\n",
    "lithIntVar.data[islith] = 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "#Material properties\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the paper, Crameri and Tackley give the dimensionless cohesion as well as the dimensionless yield stress gradient. But the latter is given as a function of dimensionless (lithostatic) pressure, whereas it is easier to use dimensionless depth. Easy, multiply the dimensionless depth by $\\rho g D$, divide by the stress scale, $\\frac{\\eta \\kappa}{D^2}$ then use the same dimensionless yeild stress gradient ($\\mu$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# The yeilding of the upper slab is dependent on the strain rate.\n",
    "strainRate_2ndInvariant = fn.tensor.second_invariant( \n",
    "                            fn.tensor.symmetric( \n",
    "                            velocityField.fn_gradient ))\n",
    "\n",
    "\n",
    "coordinate = fn.input()\n",
    "depth = 1. - coordinate[1]\n",
    "\n",
    "#Determine yield criterion for depth (rather than pressure as given in Crameri)\n",
    "#Scaling is same as van Heck and Tackley, EPSL, 2011\n",
    "lithopressuregrad = dp.rho*dp.g*(dp.LS)**3/(dp.eta0*dp.k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Check important paramters\n",
    "print(ndp.E, ndp.V,ndp.TS,ndp.RD, ndp.TR, ndp.cohesion)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#ndp.up_visc/ndp.low_visc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#lithopressuregrad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "############\n",
    "#Mantle\n",
    "############\n",
    "\n",
    "#Linear viscosity\n",
    "arhennius = fn.misc.min(ndp.up_visc,fn.math.exp(((ndp.E + ndp.V*(1.-coordinate[1]))/\n",
    "                                         (temperatureField + ndp.TS)) - ((ndp.E + ndp.V*(1.- ndp.RD))/(ndp.TR + ndp.TS))))\n",
    "\n",
    "#Psuedo-plastic \n",
    "ys =  ndp.cohesion + (depth*ndp.fc*lithopressuregrad)\n",
    "#ys =  ndp.fc*lithopressuregrad*(30e3/dp.LS) # this is the byerlee strength at 30 km\n",
    "yss = fn.misc.max(ndp.cohesion, ys)\n",
    "plasticvisc = yss*(math.sqrt(2))/(strainRate_2ndInvariant*2.)\n",
    "plastic = fn.misc.max(ndp.low_visc,plasticvisc)\n",
    "#combine these\n",
    "mantleviscosityFn = fn.exception.SafeMaths(fn.misc.min(arhennius, plastic))\n",
    "\n",
    "############\n",
    "#crust\n",
    "############\n",
    "\n",
    "\n",
    "\n",
    "ysc = (ndp.cohesion/ndp.cohesion_reduce) + (depth*(ndp.fc/100.)*lithopressuregrad)\n",
    "#ysc = ys/100.\n",
    "ycs = fn.misc.max((ndp.cohesion/ndp.cohesion_reduce), ysc)\n",
    "crustplasticvisc = ycs*(math.sqrt(2))/(strainRate_2ndInvariant*2.)\n",
    "crustplastic = fn.misc.max(ndp.low_visc,crustplasticvisc) \n",
    "#crustviscosityFn = fn.exception.SafeMaths(fn.misc.min(arhennius, crustplastic))\n",
    "crustviscosityFn = fn.exception.SafeMaths(fn.misc.min(1., crustplastic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the rheology implemented manually above can also be set up using an Underworld2 function, as follows:\n",
    "```python\n",
    "fn_stress =  2.*arhennius*uw.function.tensor.symmetric(velocityField.fn_gradient )\n",
    "plasticvisc = fn.rheology.stress_limiting_viscosity(fn_stress,ys,arhennius)\n",
    "plastic = fn.misc.max(1e-4,plasticvisc)\n",
    "mantleviscosityFn = fn.exception.SafeMaths(fn.misc.min(arhennius, plastic))\n",
    "stokesPIC.fn_viscosity = mantleviscosityFn\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up material properties\n",
    "====\n",
    "\n",
    "Here the functions for density, viscosity etc. are set. These functions and/or values are preserved for the entire simulation time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Here we set a viscosity value of '1.' for both materials\n",
    "viscosityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:ndp.StAeta0, \n",
    "                                    lithosphereIndex:mantleviscosityFn, \n",
    "                                    crustIndex:crustviscosityFn,\n",
    "                                    mantleIndex:mantleviscosityFn} )\n",
    "\n",
    "densityMapFn = fn.branching.map( fn_key = materialVariable,\n",
    "                         mapping = {airIndex:ndp.StA, \n",
    "                                    lithosphereIndex:ndp.RA*temperatureField, \n",
    "                                    crustIndex:ndp.RA*temperatureField, \n",
    "                                    mantleIndex:ndp.RA*temperatureField} )\n",
    "\n",
    "# Define our gravity using a python tuple (this will be automatically converted to a function)\n",
    "gravity = ( 0.0, 1.0 )\n",
    "\n",
    "buoyancyFn = gravity*densityMapFn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build the Stokes system, solvers, advection-diffusion\n",
    "------\n",
    "\n",
    "Setup linear Stokes system to get the initial velocity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stokesPIC = uw.systems.Stokes( velocityField = velocityField, \n",
    "                               pressureField = pressureField,\n",
    "                               #swarm         = gSwarm, \n",
    "                               conditions    = [freeslipBC,],\n",
    "                               fn_viscosity   = arhennius, \n",
    "                               fn_bodyforce   = buoyancyFn,\n",
    "                               swarm=gSwarm)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#We do one solve with linear viscosity to get the initial strain rate invariant. \n",
    "#This solve step also calculates a 'guess' of the the velocity field based on the linear system, \n",
    "#which is used later in the non-linear solver.\n",
    "\n",
    "solver = uw.systems.Solver(stokesPIC)\n",
    "# If not doing a restart, do a solve on the non-plastic system\n",
    "if not checkpointLoad:\n",
    "    solver.solve()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.options"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(solver.options.A11.list())\n",
    "print(solver.options.scr.list())\n",
    "print(solver.options.mg.list())\n",
    "print(solver.options.mg_accel.list())\n",
    "print(solver.options.main.list())\n",
    "print(solver.options.rhsA11.list())\n",
    "print(solver.options.backsolveA11.list())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "####################\n",
    "#Add the non-linear viscosity to the Stokes system\n",
    "stokesPIC.fn_viscosity = viscosityMapFn\n",
    "###################\n",
    "\n",
    "#Set more advanced solver option\n",
    "solver.options.main.Q22_pc_type='gkgdiag'\n",
    "#solver.options.A11.ksp_rtol=1e-2\n",
    "#solver.options.scr.ksp_rtol=1e-3\n",
    "#solver.options.A11.ksp_type=\"cg\"\n",
    "solver.options.scr.use_previous_guess = True\n",
    "#solver.options.scr.ksp_set_min_it_converge = 1\n",
    "#solver.options.main.penalty=10.0\n",
    "\n",
    "#solver.options.mg.levels = 3\n",
    "#solver.options.main.remove_constant_pressure_null_space=True\n",
    "#solver.options.main.penalty = 1e2\n",
    "\n",
    "#solver.options.A11.ksp_rtol=1e-4\n",
    "#solver.options.scr.ksp_rtol=1e-4\n",
    "\n",
    "solver.options.A11.ksp_monitor=''\n",
    "solver.options.A11.ksp_converged_reason=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print \"## Solver Config\"\n",
    "print solver.options.main.list()\n",
    "print \"### A11 Config\"\n",
    "print solver.options.A11.list()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solve non-linear system for pressure and velocity using Picard iteration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "solver.solve(nonLinearIterate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Now check the stress.\n",
    "fn_stress = 2.*mantleviscosityFn*uw.function.tensor.symmetric(velocityField.fn_gradient)\n",
    "fn_minmax_inv = fn.view.min_max(fn.tensor.second_invariant(fn_stress))\n",
    "ignore = fn_minmax_inv.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "fn_minmax_inv.max_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#np.isclose(fn_minmax_inv.max_global(), ys, rtol=1e-03)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#figTemp = glucifer.Figure()\n",
    "#figTemp.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "#figTemp.append( glucifer.objects.VectorArrows(mesh,velocityField, arrowHead=0.2, scaling=0.0005))\n",
    "\n",
    "#figTemp.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an advective-diffusive system\n",
    "=====\n",
    "\n",
    "Setup the system in underworld by flagging the temperature and velocity field variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Create advdiff system\n",
    "\n",
    "advDiff = uw.systems.AdvectionDiffusion( phiField       = temperatureField, \n",
    "                                         phiDotField    = temperatureDotField, \n",
    "                                         velocityField  = velocityField,\n",
    "                                         fn_sourceTerm    = 20.0,\n",
    "                                         fn_diffusivity = 1.0, \n",
    "                                         conditions     = [neumannTempBC, dirichTempBC] )\n",
    "\n",
    "\n",
    "\n",
    "advector = uw.systems.SwarmAdvector( swarm         = gSwarm, \n",
    "                                     velocityField = velocityField, \n",
    "                                     order         = 1)\n",
    "\n",
    "#Switch particle escape on, this will also trigger the inflow population control \n",
    "gSwarm.particleEscape = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics for benchmark\n",
    "=====\n",
    "\n",
    "Define functions to be used in the time loop. For cases 1-4, participants were asked to report a number of diagnostic quantities to be measured after reaching steady state:\n",
    "\n",
    "* Average temp... $$  \\langle T \\rangle  = \\int^1_0 \\int^1_0 T \\, dxdy $$\n",
    "* Top and bottom Nusselt numbers... $$N = \\int^1_0 \\frac{\\partial T}{\\partial y} \\rvert_{y=0/1} \\, dx$$\n",
    "* RMS velocity over the whole domain, surface and max velocity at surface\n",
    "* max and min viscosity over the whole domain\n",
    "* average rate of work done against gravity...$$\\langle W \\rangle = \\int^1_0 \\int^1_0 T u_y \\, dx dy$$\n",
    "* and the average rate of viscous dissipation...$$\\langle \\Phi \\rangle = \\int^1_0 \\int^1_0 \\tau_{ij} \\dot \\epsilon_{ij} \\, dx dy$$\n",
    "\n",
    "* In steady state, if thermal energy is accurately conserved, the difference between $\\langle W \\rangle$ and $\\langle \\Phi \\rangle / Ra$ must vanish, so also reported is the percentage error: \n",
    "\n",
    "$$ \\delta = \\frac{\\lvert \\langle W \\rangle - \\frac{\\langle \\Phi \\rangle}{Ra} \\rvert}{max \\left(  \\langle W \\rangle,  \\frac{\\langle \\Phi \\rangle}{Ra}\\right)} \\times 100% $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Setup some Integrals. We want these outside the main loop...\n",
    "tempVariable = gSwarm.add_variable( dataType=\"double\", count=1 )\n",
    "tempVariable.data[:] = temperatureField.evaluate(gSwarm)[:]\n",
    "tempint = uw.utils.Integral((tempVariable*rockIntVar), mesh)\n",
    "\n",
    "\n",
    "areaint = uw.utils.Integral((1.*rockIntVar),mesh)\n",
    "\n",
    "v2int = uw.utils.Integral(fn.math.dot(velocityField,velocityField)*rockIntVar, mesh)\n",
    "\n",
    "\n",
    "dwint = uw.utils.Integral(temperatureField*velocityField[1]*rockIntVar, mesh)\n",
    "\n",
    "\n",
    "sinner = fn.math.dot(strainRate_2ndInvariant,strainRate_2ndInvariant)\n",
    "vdint = uw.utils.Integral((4.*viscosityMapFn*sinner)*rockIntVar, mesh)\n",
    "vdintair = uw.utils.Integral((4.*viscosityMapFn*sinner)*airIntVar, mesh)\n",
    "vdintlith = uw.utils.Integral((4.*viscosityMapFn*sinner)*lithIntVar, mesh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#These should differ if the the map function assigns different properties to bulk mantle\n",
    "\n",
    "print(uw.utils.Integral((4.*mantleviscosityFn*sinner)*rockIntVar, mesh).evaluate()[0])\n",
    "print(uw.utils.Integral((4.*viscosityMapFn*sinner)*rockIntVar, mesh).evaluate()[0])\n",
    "\n",
    "print(uw.utils.Integral((4.*mantleviscosityFn*sinner)*airIntVar, mesh).evaluate()[0])\n",
    "print(uw.utils.Integral((4.*viscosityMapFn*sinner)*airIntVar, mesh).evaluate()[0])\n",
    "\n",
    "print(uw.utils.Integral((4.*mantleviscosityFn*sinner)*lithIntVar, mesh).evaluate()[0])\n",
    "print(uw.utils.Integral((4.*viscosityMapFn*sinner)*lithIntVar, mesh).evaluate()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def avg_temp():\n",
    "    return tempint.evaluate()[0]/areaint.evaluate()[0]\n",
    "\n",
    "#This one gets cleaned up when Surface integrals are available\n",
    "def nusselt(tempfield, swarm, dx):\n",
    "    #Update the swarm variable\n",
    "    tempgrad = tempfield.fn_gradient\n",
    "    valcheck = tempgrad[1].evaluate(swarm)\n",
    "    if valcheck is None:\n",
    "        vals = np.array(0, dtype='float64')\n",
    "    else:\n",
    "        vals = valcheck.sum()*dx\n",
    "    return vals\n",
    "\n",
    "def rms():\n",
    "    return math.sqrt(v2int.evaluate()[0]/areaint.evaluate()[0])\n",
    "\n",
    "#This one gets cleaned up when Surface integrals are available\n",
    "def rms_surf(swarm, dx):\n",
    "    rmsmaxfn = fn.math.dot(velocityField,velocityField)\n",
    "    rmscheck = rmsmaxfn.evaluate(swarm)\n",
    "    if rmscheck is None:\n",
    "        #print \"watch out\"\n",
    "        rmsvals = np.array(0, dtype='float64')\n",
    "    else:\n",
    "        rmsvals = np.sqrt(rmscheck.sum()*dx)\n",
    "        #print \"okay\"\n",
    "    return rmsvals\n",
    "\n",
    "def max_vx_surf(velfield, swarm):\n",
    "    check = velfield[0].evaluate(swarm)\n",
    "    if check is None:\n",
    "        return 0.\n",
    "    else:\n",
    "        return check.max()\n",
    "\n",
    "\n",
    "#def max_vy_surf(velfield, swarm):\n",
    "#    surfvelxmaxfn = fn.view.min_max(velfield[1])\n",
    "#    surfvelxmaxfn.evaluate(swarm)\n",
    "#    return surfvelxmaxfn.max_global()\n",
    "\n",
    "def gravwork(workfn):\n",
    "    return workfn.evaluate()[0]\n",
    "\n",
    "def viscdis(vdissfn):\n",
    "    return vdissfn.evaluate()[0]\n",
    "\n",
    "def visc_extr(viscfn):\n",
    "    vuviscfn = fn.view.min_max(viscfn)\n",
    "    vuviscfn.evaluate(gSwarm)\n",
    "    return vuviscfn.max_global(), vuviscfn.min_global()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Fields for saving data / fields\n",
    "\n",
    "rmsField = uw.mesh.MeshVariable( mesh=mesh,   nodeDofCount=1)\n",
    "rmsfn = fn.math.sqrt(fn.math.dot(velocityField,velocityField))\n",
    "rmsdata = rmsfn.evaluate(mesh)\n",
    "rmsField.data[:] = rmsdata \n",
    "\n",
    "viscField = uw.mesh.MeshVariable( mesh=mesh,   nodeDofCount=1)\n",
    "viscdata = mantleviscosityFn.evaluate(mesh)\n",
    "viscField.data[:] = viscdata\n",
    "\n",
    "\n",
    "strainrateField = uw.mesh.MeshVariable( mesh=mesh,   nodeDofCount=1)\n",
    "srtdata = fn.tensor.second_invariant( \n",
    "                    fn.tensor.symmetric( \n",
    "                        velocityField.fn_gradient ))\n",
    "rostfield = srtdata.evaluate(mesh)\n",
    "strainrateField.data[:] = rostfield\n",
    "\n",
    "viscVariable = gSwarm.add_variable( dataType=\"float\", count=1 )\n",
    "viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Images\n",
    "figEta = glucifer.Figure()\n",
    "figEta.append( glucifer.objects.Points(gSwarm,viscVariable, logScale=True))\n",
    "\n",
    "\n",
    "figMat = glucifer.Figure()\n",
    "figMat.append( glucifer.objects.Points(gSwarm,materialVariable, colours='brown white blue red'))\n",
    "figMat.append( glucifer.objects.Mesh(mesh))\n",
    "\n",
    "\n",
    "figStrainRate = glucifer.Figure()\n",
    "figStrainRate.append( glucifer.objects.Surface(mesh, strainRate_2ndInvariant, logScale=True))\n",
    "\n",
    "\n",
    "figVelocityMag = glucifer.Figure()\n",
    "figVelocityMag.append( glucifer.objects.Surface(mesh, fn.math.dot(velocityField,velocityField))\n",
    ")\n",
    "figTemp = glucifer.Figure()\n",
    "figTemp.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "\n",
    "\n",
    "\n",
    "#Pack some stuff into a database as well\n",
    "figDb = glucifer.Figure()\n",
    "figDb.append( glucifer.objects.Points(gSwarm,viscVariable, logScale=True, colours='brown white blue'))\n",
    "figDb.append( glucifer.objects.Points(gSwarm,materialVariable, colours='brown white blue red'))\n",
    "figDb.append( glucifer.objects.Mesh(mesh))\n",
    "figDb.append( glucifer.objects.VectorArrows(mesh,velocityField, arrowHead=0.2, scaling=0.002))\n",
    "figDb.append( glucifer.objects.Surface(mesh, strainRate_2ndInvariant, logScale=True, colours='brown white blue'))\n",
    "figDb.append( glucifer.objects.Surface(mesh, temperatureField))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Main simulation loop\n",
    "=======\n",
    "\n",
    "The main time stepping loop begins here. Before this the time and timestep are initialised to zero and the output statistics arrays are set up. Also the frequency of outputting basic statistics to the screen is set in steps_output.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pics = uw.swarm.PICIntegrationSwarm(gSwarm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def checkpoint1(step, checkpointPath,filename, filewrites):\n",
    "    path = checkpointPath + str(step) \n",
    "    os.mkdir(path)\n",
    "    ##Write and save the file, if not already a writing step\n",
    "    if not step % filewrites == 0:\n",
    "        filename.write((13*'%-15s ' + '\\n') % (realtime, Viscdis, float(Nu0glob), float(Nu1glob), Avg_temp, \n",
    "                                              Rms,Rmsurfglob,Max_vx_surf,Gravwork, etamax, etamin, Viscdisair, Viscdislith))\n",
    "    filename.close()\n",
    "    shutil.copyfile(os.path.join(outputPath, outputFile), os.path.join(path, outputFile))\n",
    "\n",
    "\n",
    "def checkpoint2(step, checkpointPath, swarm, filename, varlist = [materialVariable], varnames = ['materialVariable']):\n",
    "    path = checkpointPath + str(step) \n",
    "    velfile = \"velocityField\" + \".hdf5\"\n",
    "    tempfile = \"temperatureField\" + \".hdf5\"\n",
    "    pressfile = \"pressureField\" + \".hdf5\"\n",
    "    velocityField.save(os.path.join(path, velfile))\n",
    "    temperatureField.save(os.path.join(path, tempfile))\n",
    "    pressureField.save(os.path.join(path, pressfile))\n",
    "    swarm.save(os.path.join(path, \"swarm.h5\") ) \n",
    "    for ix in range(len(varlist)):\n",
    "        varb = varlist[ix]\n",
    "        varb.save(os.path.join(path,varnames[ix] + \".h5\"))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "advector.get_max_dt(), advDiff.get_max_dt()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "start = time.clock()\n",
    "# setup summary output file (name above)\n",
    "if checkpointLoad:\n",
    "    if uw.rank() == 0:\n",
    "        shutil.copyfile(os.path.join(checkpointLoadDir, outputFile), outputPath+outputFile)\n",
    "    comm.Barrier()\n",
    "    f_o = open(os.path.join(outputPath, outputFile), 'a')\n",
    "    prevdata = np.genfromtxt(os.path.join(outputPath, outputFile), skip_header=0, skip_footer=0)\n",
    "    if len(prevdata.shape) == 1: #this is in case there is only one line in previous file\n",
    "        realtime = prevdata[0]\n",
    "    else:\n",
    "        realtime = prevdata[prevdata.shape[0]-1, 0]\n",
    "    step = int(checkpointLoadDir.split('/')[-1])\n",
    "    timevals = [0.]\n",
    "else:\n",
    "    f_o = open(outputPath+outputFile, 'w')\n",
    "    realtime = 0.\n",
    "    step = 0\n",
    "    timevals = [0.]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# initialise timer for computation\n",
    "startMain = time.clock()\n",
    "# Perform steps\n",
    "while realtime < 0.05:\n",
    "#while step < 5:\n",
    "    #Enter non-linear loop\n",
    "    print step\n",
    "    solver.solve(nonLinearIterate=True)\n",
    "    dt = advDiff.get_max_dt()\n",
    "    if step == 0:\n",
    "        dt = 0.\n",
    "    #start = time.clock()\n",
    "    advDiff.integrate(dt)\n",
    "    #machine_time = (time.clock()-start)\n",
    "    #print(\"total advDiff time is: \" + str(machine_time))\n",
    "    # Advect swarm using this timestep size\n",
    "    #start = time.clock()\n",
    "    advector.integrate(dt)\n",
    "    #machine_time = (time.clock()-start)\n",
    "    #print(\"total advector time is: \" + str(machine_time))\n",
    "    # Increment\n",
    "    realtime += dt\n",
    "    step += 1\n",
    "    timevals.append(realtime)\n",
    "    \n",
    "    ################\n",
    "    #Update temperature field in the air region\n",
    "    ################\n",
    "    if (step % sticky_air_temp == 0):\n",
    "        for index, coord in enumerate(mesh.data):\n",
    "            if coord[1] >= 1.:\n",
    "                temperatureField.data[index] = dp.TS/dp.deltaT\n",
    " \n",
    "    ################\n",
    "    #Particle update\n",
    "    ###############\n",
    "    if (step % swarm_update == 0) or (step % metric_output == 0): #These updates should be done before any metric output\n",
    "        #These swarm variables get updated first, as they are used to determine material changes\n",
    "        particledepths = 1. - gSwarm.particleCoordinates.data[:,1]\n",
    "        particletemps = temperatureField.evaluate(gSwarm)[:,0]\n",
    "        conditionmap['depthcondition']['data'] = particledepths\n",
    "        conditionmap['avgtempcondition']['data'] = particletemps\n",
    "        ################\n",
    "        number_updated = 0\n",
    "        for particleID in range(gSwarm.particleCoordinates.data.shape[0]):\n",
    "            check = update_swarm(DG, particleID)\n",
    "            if check > -1:\n",
    "                number_updated += 1\n",
    "                #if check == 0:\n",
    "                #    print \"from \" + str(materialVariable.data[particleID]) + \" to \" + str(check)\n",
    "                materialVariable.data[particleID] = check\n",
    "            else:\n",
    "                pass\n",
    "        #Also update those integration swarms\n",
    "        rockIntVar.data[:] = 0.\n",
    "        notair = np.where(materialVariable.data != airIndex)\n",
    "        rockIntVar.data[notair] = 1.\n",
    "        airIntVar.data[:] = 0.\n",
    "        notrock = np.where(materialVariable.data == airIndex)\n",
    "        airIntVar.data[notrock] = 1.\n",
    "        lithIntVar.data[:] = 0.\n",
    "        islith = np.where((materialVariable.data == lithosphereIndex) | (materialVariable.data == crustIndex))\n",
    "        lithIntVar.data[islith] = 1.\n",
    "\n",
    "    ################            \n",
    "    # Calculate the Metrics, only on 1 of the processors:\n",
    "    ################\n",
    "    if (step % metric_output == 0):\n",
    "        ###############\n",
    "        #Swarm - based Metrics\n",
    "        ###############\n",
    "        tempVariable.data[:] = temperatureField.evaluate(gSwarm)[:]\n",
    "        Avg_temp = avg_temp()\n",
    "        Rms = rms()\n",
    "        Gravwork = gravwork(dwint)\n",
    "        Viscdis = viscdis(vdint)\n",
    "        Viscdisair = viscdis(vdintair)\n",
    "        Viscdislith = viscdis(vdintlith)\n",
    "        etamax, etamin = visc_extr(viscosityMapFn)\n",
    "        #These are the ones that need mpi4py treatment\n",
    "        Nu0loc = nusselt(temperatureField, baseintswarm, dx)\n",
    "        Nu1loc = nusselt(temperatureField, surfintswarm, dx)\n",
    "        Rmsurfloc = rms_surf(surfintswarm, dx)\n",
    "        Max_vx_surfloc = np.array(max_vx_surf(velocityField, surfintswarm),'d') #This float needed to be an array to play with mpi4py\n",
    "        #Setup the global output arrays\n",
    "        dTp = Nu0loc.dtype\n",
    "        Nu0glob = np.array(0, dtype=dTp)\n",
    "        dTp = Nu1loc.dtype\n",
    "        Nu1glob = np.array(0, dtype=dTp)\n",
    "        dTp = Rmsurfloc.dtype\n",
    "        Rmsurfglob = np.array(0, dtype=dTp)\n",
    "        dTp = Max_vx_surfloc.dtype\n",
    "        Max_vx_surfglob = np.array(0.0,dtype=dTp)   \n",
    "        #Do global operation ... sum, or max\n",
    "        comm.Allreduce(Nu0loc, Nu0glob, op=MPI.SUM)\n",
    "        comm.Allreduce(Nu1loc, Nu1glob, op=MPI.SUM)\n",
    "        comm.Allreduce(Rmsurfloc, Rmsurfglob, op=MPI.SUM)\n",
    "        comm.Allreduce([Max_vx_surfloc, MPI.DOUBLE],[Max_vx_surfglob, MPI.DOUBLE],op=MPI.MAX)      \n",
    "        # output to summary text file\n",
    "        if uw.rank()==0:\n",
    "            f_o.write((13*'%-15s ' + '\\n') % (realtime, Viscdis, float(Nu0glob), float(Nu1glob), Avg_temp, \n",
    "                                              Rms,Rmsurfglob,Max_vx_surfglob,Gravwork, etamax, etamin, Viscdisair, Viscdislith))\n",
    "    ################\n",
    "    #Gldb output\n",
    "    ################ \n",
    "    if (step % gldbs_output == 0) & (writeFiles == True):\n",
    "        #Rebuild any necessary swarm variables\n",
    "        viscVariable.data[:] = viscosityMapFn.evaluate(gSwarm)\n",
    "        #Write gldbs\n",
    "        fnamedb = \"dbFig\" + \"_\" + str(ModIt) + \"_\" + str(step) + \".gldb\"\n",
    "        fullpath = os.path.join(outputPath + \"gldbs/\" + fnamedb)\n",
    "        figDb.show()\n",
    "        figDb.save_database(fullpath)\n",
    "    ################\n",
    "    #Also repopulate entire swarm periodically\n",
    "    ################\n",
    "    if step % swarm_repop == 0:\n",
    "        pics.repopulate()\n",
    "    ################\n",
    "    #Checkpoint\n",
    "    ################\n",
    "    if step % checkpoint_every == 0:\n",
    "        if uw.rank() == 0:\n",
    "            checkpoint1(step, checkpointPath,f_o, metric_output)           \n",
    "        checkpoint2(step, checkpointPath, gSwarm, f_o, varlist = varlist, varnames = varnames)\n",
    "        f_o = open(os.path.join(outputPath, outputFile), 'a') #is this line supposed to be here?\n",
    "\n",
    "        \n",
    "        \n",
    "f_o.close()\n",
    "print 'step =',step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figTemp = glucifer.Figure()\n",
    "figTemp.append( glucifer.objects.Surface(mesh, temperatureField))\n",
    "#figTemp.append( glucifer.objects.Mesh(mesh))\n",
    "\n",
    "#figTemp.append( glucifer.objects.VectorArrows(mesh,velocityField, arrowHead=0.2, scaling=0.01))\n",
    "figTemp.save_database('test.gldb')\n",
    "figTemp.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#figVelocityMag = glucifer.Figure(figsize=(1024,384))\n",
    "#figVelocityMag.append( glucifer.objects.Surface(mesh, fn.math.dot(velocityField,velocityField), logScale=True))\n",
    "#figVelocityMag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#figVelocityMag = glucifer.Figure(figsize=(1024,384))\n",
    "#figVelocityMag.append( glucifer.objects.Surface(mesh, temperatureField, logScale=True, valueRange=[1e-15,5e-8]) )\n",
    "#figVelocityMag.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#figVelocityMag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#figSwarm = glucifer.Figure(figsize=(1024,384))\n",
    "#figSwarm.append( glucifer.objects.Points(gSwarm,materialVariable, colours='brown white blue red'))\n",
    "#figSwarm.append( glucifer.objects.Mesh(mesh))\n",
    "#figSwarm.show()\n",
    "#figSwarm.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "figDb.show()\n",
    "figDb.save_database('test.gldb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "machine_time = (time.clock()-start)\n",
    "print(\"total time is: \" + str(machine_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Sanity check for periodic conditions\n",
    "#velocityField.evaluate(TWalls)[:,0].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#print(\"TWalls x vel is: \" + str(velocityField.evaluate(TWalls)[:,0].max()))\n",
    "#print(\"IWalls x vel is: \" + str(velocityField.evaluate(IWalls)[:,0].max()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#ts = ((D*1e3)**2)/k\n",
    "#secperyear = (3600*24*365)\n",
    "#dt*ts/secperyear\n",
    "\n",
    "#2.25895987733e-05*ts/secperyear"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
